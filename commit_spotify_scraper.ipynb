{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":8859451,"datasetId":5328501,"databundleVersionId":9019428},{"sourceType":"datasetVersion","sourceId":8851076,"datasetId":5315740,"databundleVersionId":9010680}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ishansrivastava1308/commit-notebook-of-spotify-data-scraper?scriptVersionId=186854500\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install pytube --upgrade\n!pip install spotipy\n!pip install ytmusicapi\n# !pip install yt-dlp\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\n# Suppress the specific FutureWarning\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"The behavior of DataFrame concatenation with empty or all-NA entries is deprecated.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:41:10.909052Z","iopub.execute_input":"2024-07-04T16:41:10.909567Z","iopub.status.idle":"2024-07-04T16:41:10.916683Z","shell.execute_reply.started":"2024-07-04T16:41:10.909525Z","shell.execute_reply":"2024-07-04T16:41:10.915321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ytmusicapi import YTMusic\nimport ytmusicapi\nfrom pprint import pprint\nimport os\nfrom pytube import YouTube\nimport urllib.request\nimport requests\nimport string\nfrom spotipy.client import Spotify\nfrom spotipy import SpotifyOAuth\nfrom spotipy.oauth2 import SpotifyOauthError, SpotifyClientCredentials\nimport pandas as pd\nimport numpy as np\nimport json\nimport concurrent.futures\nimport time\nimport threading\nfrom pydub import AudioSegment\nfrom IPython.display import Audio\nfrom dotenv import load_dotenv\nimport multiprocessing\nfrom tqdm import tqdm\nfrom IPython.display import Audio\nfrom tensorflow.keras.utils import Progbar\n# import yt_dlp","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:45:07.835171Z","iopub.execute_input":"2024-07-04T16:45:07.836482Z","iopub.status.idle":"2024-07-04T16:45:07.847072Z","shell.execute_reply.started":"2024-07-04T16:45:07.836431Z","shell.execute_reply":"2024-07-04T16:45:07.845313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytube.innertube as pti","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:45:08.035537Z","iopub.execute_input":"2024-07-04T16:45:08.035958Z","iopub.status.idle":"2024-07-04T16:45:08.042244Z","shell.execute_reply.started":"2024-07-04T16:45:08.035926Z","shell.execute_reply":"2024-07-04T16:45:08.040721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pti._token_file = '/kaggle/working/tokens.json'\npti._cache_dir = '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:45:08.228636Z","iopub.execute_input":"2024-07-04T16:45:08.229046Z","iopub.status.idle":"2024-07-04T16:45:08.235577Z","shell.execute_reply.started":"2024-07-04T16:45:08.229013Z","shell.execute_reply":"2024-07-04T16:45:08.233987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Kaggle Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:00.138078Z","iopub.execute_input":"2024-07-04T16:46:00.138644Z","iopub.status.idle":"2024-07-04T16:46:00.527042Z","shell.execute_reply.started":"2024-07-04T16:46:00.138601Z","shell.execute_reply":"2024-07-04T16:46:00.525739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta = dict(\n    id=\"ishansrivastava1308/spotify-dataset\",\n    title=\"Spotify Dataset\",\n    isPrivate=True,\n    licenses=[dict(name=\"other\")]\n)\nos.makedirs('/kaggle/working/dataset', exist_ok = True)\nwith open(os.path.join('dataset','dataset-metadata.json'), 'w') as f:\n    json.dump(meta, f)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:00.529642Z","iopub.execute_input":"2024-07-04T16:46:00.530049Z","iopub.status.idle":"2024-07-04T16:46:00.538535Z","shell.execute_reply.started":"2024-07-04T16:46:00.530014Z","shell.execute_reply":"2024-07-04T16:46:00.536804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets create -p /kaggle/working/dataset --dir-mode tar","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:00.540431Z","iopub.execute_input":"2024-07-04T16:46:00.540915Z","iopub.status.idle":"2024-07-04T16:46:00.55355Z","shell.execute_reply.started":"2024-07-04T16:46:00.540875Z","shell.execute_reply":"2024-07-04T16:46:00.551889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets version -m\"Added more songs and data\" -p /kaggle/working/dataset --dir-mode tar","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:00.609145Z","iopub.execute_input":"2024-07-04T16:46:00.610211Z","iopub.status.idle":"2024-07-04T16:46:00.620201Z","shell.execute_reply.started":"2024-07-04T16:46:00.610159Z","shell.execute_reply":"2024-07-04T16:46:00.617935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scrapper Class Definition","metadata":{}},{"cell_type":"code","source":"df_columns = ['track_name', 'track_id', 'track_number', 'disc_number', 'duration_ms',\n       'explicit', 'popularity', 'preview_url', 'isrc', 'album_name',\n       'album_id', 'album_type', 'album_total_tracks', 'album_release_date',\n       'album_release_date_precision', 'album_images', 'popular_artist',\n       'popular_artist_id', 'artist_names', 'artist_ids', 'combined_genres',\n       'artist_popularity', 'artist_followers', 'external_url', 'acousticness',\n       'danceability', 'energy', 'instrumentalness', 'key', 'liveness',\n       'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence',\n       'lyrics', 'audio_file_path', 'video_id']","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:00.859499Z","iopub.execute_input":"2024-07-04T16:46:00.859961Z","iopub.status.idle":"2024-07-04T16:46:00.867887Z","shell.execute_reply.started":"2024-07-04T16:46:00.859925Z","shell.execute_reply":"2024-07-04T16:46:00.866381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class YTScraper:\n    def __init__(\n        self,\n        token_file_path=\"oauth.json\",\n    ):\n        self.yt_music = YTMusic(token_file_path)\n        YouTube(\n            \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n            use_oauth=True,\n            allow_oauth_cache=True,\n        ).streams.filter(only_audio=True).first().download()\n\n    def get_search_results(self, search_str):\n        return self.yt_music.search(search_str, filter=\"songs\")\n    \n    def get_best_video_id(self,search_str):\n        search_result = self.get_search_results(search_str=search_str)\n        video_id = None\n        try:\n            for item in search_result:\n                if item[\"resultType\"] in [\"song\"] and item[\"category\"] == \"Songs\":\n                    video_id = item[\"videoId\"]\n                    break\n        except Exception as e:\n            print(f\"Exception in get_best_video_id message : {e}\")\n        return video_id\n    \n    def get_song_from_video_id(self,video_id,output_path = './', audio_format = 'mp3', target_sr = 16000, num_channels = 1):\n        os.makedirs(output_path, exist_ok=True)\n        temp_file = os.path.join(output_path, f\"{video_id}.mp4\")\n        download_path = os.path.join(output_path,f\"{video_id}.{audio_format}\")\n        try:\n            yt = YouTube(f\"https://youtube.com/watch?v={video_id}\")\n            yt.streams.filter(only_audio=True).first().download(\n                output_path=output_path, filename=f\"{video_id}.mp4\"\n            )\n            if os.path.exists(temp_file):\n                #         print(f\"Downloaded successfully: {temp_file}\")\n                audio = AudioSegment.from_file(temp_file, format=\"mp4\")\n                audio = audio.set_frame_rate(target_sr)\n                audio = audio.set_channels(num_channels)\n                wav_path = temp_file[:-4] + audio_format\n                audio.export(wav_path, format=audio_format)\n                os.remove(temp_file)\n            return download_path\n        except Exception as e:\n            return None\n            \n    def get_lyrics_video_id(self, video_id):\n        video = self.yt_music.get_watch_playlist(\n            videoId=video_id,\n        )\n        lyrics_id = video[\"lyrics\"]\n        lyrics = None\n        if lyrics_id:\n            try:\n                lyrics = self.yt_music.get_lyrics(lyrics_id)\n            except:\n                pass\n        return lyrics\n    \n#     def threaded_download_song_by_video_id_list(\n#         self, video_id_list, output_path=\"songs\", max_workers=50\n#     ):\n#         data = []\n#         with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n#             # List of tasks to be executed by the thread pool\n#             tasks = []\n#                         output_path_args = [output_path] * len(video_id_list)\n\n#             for args in zip(video_id_list, output_path_args):\n#                 fut = executor.submit(self.download_song_by_video_id, *args)\n\n#             tasks = [\n                \n#             ]\n#             success = 0\n#             fails = 0\n\n#             with tqdm(total=len(video_id_list)) as pbar:\n#                 for future in concurrent.futures.as_completed(tasks):\n#                     try:\n#                         data.append(future.result())\n#                         pbar.update(1)\n#                         success += 1\n#                     except Exception as exc:\n#                         print(f\"Task generated an exception: {exc}\")\n#                         fails += 1\n#             print({\"success\": success, \"fail\": fails})\n#         return data\n\n    def scrap_by_search(\n        self,\n        search_str,\n        download_params={\n            \"include_audio\": True,\n            \"include_lyrics\": True,\n            \"output_path\": \"songs\",\n        },\n    ):\n        include_lyrics = download_params[\"include_lyrics\"]\n        include_audio = download_params[\"include_audio\"]\n        output_path = download_params[\"output_path\"]\n\n        search_result = self.get_search_results(search_str=search_str)\n        video_id = None\n        try:\n            for item in search_result:\n                if item[\"resultType\"] in [\"song\"] and item[\"category\"] == \"Songs\":\n                    video_id = item[\"videoId\"]\n                    break\n        except Exception as e:\n            print(e)\n            pass\n        lyrics = {\"lyrics\": None, \"source\": None}\n        download_path = None\n        if video_id:\n            if include_lyrics:\n                lyrics = self.get_lyrics(video_id=video_id)\n                if not lyrics:\n                    lyrics = {\"lyrics\": None, \"source\": None}\n            if include_audio:\n                download_path = self.download_song_by_video_id(\n                    video_id=video_id, output_path=output_path\n                )\n\n        return {\n            \"lyrics\": lyrics[\"lyrics\"],\n            \"audio_file_path\": download_path,\n            \"video_id\": video_id,\n        }","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:00.993068Z","iopub.execute_input":"2024-07-04T16:46:00.994628Z","iopub.status.idle":"2024-07-04T16:46:01.025178Z","shell.execute_reply.started":"2024-07-04T16:46:00.994574Z","shell.execute_reply":"2024-07-04T16:46:01.024101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SpotifyScraper_v1:\n    def __init__(\n        self,\n        client_id,\n        client_secret,\n#         redirect_uri,\n        scope = \"user-library-read playlist-read-private playlist-read-collaborative\"\n        \n    ):\n        self.df = pd.DataFrame(columns = df_columns)\n        self.yt_scraper = YTScraper()\n        self._credentials = SpotifyClientCredentials(client_id = client_id, client_secret = client_secret)\n        self.sp = Spotify(auth = self.get_access_token())\n        self.download_params = {\n            'include_audio' : True,\n            'include_lyrics' : True,\n            'output_path' : 'songs'\n        }\n            \n    def get_access_token(self):\n        # Get access token\n        access_token = self._credentials.get_access_token(as_dict = False)\n        if not access_token:\n            raise Exception(\"Access Token Not Found\")\n        return access_token\n\n    def get_auth_header(self):\n        return {\"Authorization\": \"Bearer \" + self.get_access_token()}\n    # Function to fetch user playlists\n    \n    def get_user_playlists(self):\n        print(\"Retrieving user playlists...\")\n        headers = self.get_auth_header()\n        response = requests.get(\"https://api.spotify.com/v1/me/playlists\", headers=headers)\n        response_json = response.json()\n        # for item in response_json[\"items\"]:\n        #     playlists[item[\"name\"]] = item[\"id\"]\n        print(\"Playlists retrieved successfully.\")\n        return response_json\n    \n    @staticmethod\n    def sanitize_filename(filename):\n        valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n        return ''.join(c for c in filename if c in valid_chars)\n\n    def get_track_info_by_id(self, track_id):\n        headers = self.get_auth_header()\n        response = requests.get(f\"https://api.spotify.com/v1/tracks/{track_id}\", headers=headers)\n        if not response.ok:\n            raise Exception(f\"{response.status_code} : {response.text}\")\n        response_json = response.json()\n        return response_json\n    \n    def get_playlist_info_by_id(self, playlist_id):\n        headers = self.get_auth_header()\n        response = requests.get(f\"https://api.spotify.com/v1/playlists/{playlist_id}/tracks\", headers=headers)\n        if not response.ok:\n            raise Exception(f\"{response.status_code} : {response.text}\")\n        response_json = response.json()\n        return response_json\n    \n    def get_several_track_info_by_id(self, track_ids_str):\n        for i in range(3):\n            headers = self.get_auth_header()\n            response = requests.get(f\"https://api.spotify.com/v1/tracks?ids={track_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n                if (retry_after):\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(int(retry_after) + 1)\n                else:\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(10)\n            else:\n                response_json = response.json()\n                return response_json\n    \n    def get_several_artist_info_by_id(self, artist_ids_str):\n        for i in range(3):\n            headers = self.get_auth_header()\n            response = requests.get(f\"https://api.spotify.com/v1/artists?ids={artist_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n                if (retry_after):\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(int(retry_after) + 1)\n                else:\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(10)\n            else:\n                response_json = response.json()\n                return response_json\n    \n    def get_several_audio_feature_by_id(self, track_ids_str):\n        for i in range(3):\n            headers = self.get_auth_header()\n            response = requests.get(f\"https://api.spotify.com/v1/audio-features?ids={track_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n                if (retry_after):\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(int(retry_after) + 1)\n                else:\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(10)\n            else:\n                response_json = response.json()\n                return response_json\n    \n    def destructure_artist_data(self,artists_list):\n        artist_infos = []\n        artist_genres = []\n        artist_popularities = []\n        artist_followers = []\n        for artist_obj in artists_list:\n            \n            artist_infos.append({\n                \"name\": artist_obj.get(\"name\"),\n                \"id\": artist_obj.get(\"id\"),\n                \"genres\": artist_obj.get(\"genres\", []),\n                \"popularity\": artist_obj.get(\"popularity\"),\n                \"followers\": artist_obj.get(\"followers\", {}).get(\"total\")\n            })\n            artist_genres.extend(artist_obj.get(\"genres\", []))\n            artist_popularities.append(artist_obj.get(\"popularity\"))\n            artist_followers.append(artist_obj.get(\"followers\", {}).get(\"total\"))\n\n        result = {\n            'artist_infos': artist_infos,\n            'artist_genres': artist_genres,\n            'artist_popularities': artist_popularities,\n            'artist_followers': artist_followers,\n        }\n        return result\n\n        \n    def get_playlist_by_id(self,playlist_id : str):\n        return self.sp.playlist_tracks(playlist_id = playlist_id)    \n    \n    def construct_track_info_dict(self,track_json = None, audio_features_json = None, artist_json = None):         \n        if track_json is None:\n            track_json = {}\n        if audio_features_json is None:\n            audio_features_json = {}\n        \n        most_popular_artist = {}\n        if len(artist_json['artist_infos']):\n            most_popular_artist = max(artist_json['artist_infos'], key=lambda x: x.get(\"popularity\", 0))\n        track_name = track_json.get('name', None)\n        most_popular_artist_name = most_popular_artist.get('name', '')\n        \n        \n        lyrics_audio_data = {\n            \"lyrics\": None,\n            \"audio_file_path\": None,\n            \"video_id\": None,\n        }\n        \n        if track_name:\n            search_str = f\"{track_name} {most_popular_artist_name}\"\n            lyrics_audio_data = self.yt_scraper.scrap_by_search(search_str=search_str, download_params = self.download_params)\n\n        \n        track_info = {\n            \"track_name\": track_json.get(\"name\"),\n            \"track_id\": track_json.get(\"id\"),\n            \"track_number\": track_json.get(\"track_number\"),\n            \"disc_number\": track_json.get(\"disc_number\"),\n            \"duration_ms\": track_json.get(\"duration_ms\"),\n            \"explicit\": track_json.get(\"explicit\"),\n            \"popularity\": track_json.get(\"popularity\"),\n            \"preview_url\": track_json.get(\"preview_url\"),\n            \"isrc\": track_json.get(\"external_ids\", {}).get(\"isrc\"),\n            \"album_name\": track_json.get(\"album\", {}).get(\"name\"),\n            \"album_id\": track_json.get(\"album\", {}).get(\"id\"),\n            \"album_type\": track_json.get(\"album\", {}).get(\"album_type\"),\n            \"album_total_tracks\": track_json.get(\"album\", {}).get(\"total_tracks\"),\n            \"album_release_date\": track_json.get(\"album\", {}).get(\"release_date\"),\n            \"album_release_date_precision\": track_json.get(\"album\", {}).get(\"release_date_precision\"),\n            \"album_images\": track_json.get(\"album\", {}).get(\"images\"),\n            \"popular_artist\": most_popular_artist.get(\"name\"),\n            \"popular_artist_id\": most_popular_artist.get(\"id\"),\n            \"artist_names\": [artist.get(\"name\") for artist in track_json.get(\"artists\", [])],\n            \"artist_ids\": [artist.get(\"id\") for artist in track_json.get(\"artists\", [])],\n            \"combined_genres\": list(set(artist_json.get('artist_genres', []))),\n            \"artist_popularity\": most_popular_artist.get(\"popularity\"),\n            \"artist_followers\": most_popular_artist.get(\"followers\"),\n            \"external_url\": track_json.get(\"external_urls\", {}).get(\"spotify\"),\n            \"acousticness\": audio_features_json.get(\"acousticness\"),\n            \"danceability\": audio_features_json.get(\"danceability\"),\n            \"energy\": audio_features_json.get(\"energy\"),\n            \"instrumentalness\": audio_features_json.get(\"instrumentalness\"),\n            \"key\": audio_features_json.get(\"key\"),\n            \"liveness\": audio_features_json.get(\"liveness\"),\n            \"loudness\": audio_features_json.get(\"loudness\"),\n            \"mode\": audio_features_json.get(\"mode\"),\n            \"speechiness\": audio_features_json.get(\"speechiness\"),\n            \"tempo\": audio_features_json.get(\"tempo\"),\n            \"time_signature\": audio_features_json.get(\"time_signature\"),\n            \"valence\": audio_features_json.get(\"valence\"),\n        }\n        track_info.update(lyrics_audio_data)\n        return track_info\n        \n    def _get_single_threaded_data(self,track_obj, audio_feat_obj):\n        artist_ids_list = [artist['id'] for artist in track_obj[\"artists\"]]\n        artists_id_str = ','.join(artist_ids_list[:50])\n        artists_data = self.get_several_artist_info_by_id(artists_id_str)[\"artists\"]\n        destructured_artist_data = self.destructure_artist_data(artists_list=artists_data)  \n        return self.construct_track_info_dict(track_obj, audio_feat_obj, destructured_artist_data)\n    \n    def _get_multi_threaded_data(self,tracks_json,audio_features_json, max_workers):\n        data = []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            # List of tasks to be executed by the thread pool\n            tasks = [\n                executor.submit(self._get_single_threaded_data , *args) for args in zip(tracks_json, audio_features_json)\n            ]\n            success = 0\n            fails = 0\n            \n            with tqdm(total=len(tracks_json)) as pbar:\n                for future in concurrent.futures.as_completed(tasks):\n                    try:\n                        data.append(future.result())\n                        pbar.update(1)\n                        success+=1\n                    except Exception as exc:\n                        print(f'Task generated an exception: {exc}') \n                        fails+=1\n            print({'success' : success, 'fail' : fails})\n                \n        return data\n    \n    def _get_multiprocessed_data(self,tracks_json,audio_features_json, max_workers):\n        data = []\n        with multiprocessing.Pool(processes=max_workers) as pool:\n            # List of tasks to be executed by the thread pool\n            tasks = [\n                pool.apply_async(self._get_single_threaded_data , *args) for args in zip(tracks_json, audio_features_json)\n            ]\n            \n            for task in tasks:\n                # try:\n                    result = task.get()\n                    print(result)\n                    data.append(task.get())\n                # except Exception as exc:\n                    # print(f'Task generated an exception: {exc}') \n        return data\n    \n    \n    def get_several_track_data(self, track_ids_list : list[str], parallelization = 0, max_workers = 50, include_audio = True, include_lyrics = True, output_path = \"songs\"):\n        data = []\n        track_ids_list = list(set(track_ids_list))\n        self.download_params['include_audio'] = include_audio\n        self.download_params['include_lyrics'] = include_lyrics\n        self.download_params['output_path'] = output_path\n        with tqdm(total = len(track_ids_list)) as pbar:\n            for idx in range(0,len(track_ids_list),50):\n                track_id_str = \",\".join(track_ids_list[idx:idx+50])\n                tracks_json = self.get_several_track_info_by_id(track_id_str)[\"tracks\"]\n                audio_features_json = self.get_several_audio_feature_by_id(track_ids_str=track_id_str)[\"audio_features\"]\n                if parallelization == 1:\n                    data.extend(self._get_multi_threaded_data(tracks_json,audio_features_json,max_workers))\n                elif False and parallelization == 2:\n                    data.extend(self._get_multiprocessed_data(tracks_json,audio_features_json,max_workers))\n                else:\n                    temp_data = []\n                    for track_obj, audio_feat_obj in zip(tracks_json, audio_features_json):\n                        \n                        temp_data.append(self._get_single_threaded_data(track_obj, audio_feat_obj))\n                        pbar.update(1)\n                    data.extend(temp_data)\n                    self.df = pd.concat([self.df,pd.DataFrame(temp_data)],ignore_index = True)\n        return data\n    \n    def get_track_ids_from_playlist(self,*args,**kwargs):\n        playlist_data = self.sp.playlist_tracks(*args,**kwargs)\n        return [item['track']['id'] for item in playlist_data['items']]\n    \n    def get_track_ids_from_album(self,*args,**kwargs):\n        album_data = self.sp.album_tracks(*args,**kwargs)\n        return [item['id'] for item in album_data['items']]\n    \n    \n      ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:01.263682Z","iopub.execute_input":"2024-07-04T16:46:01.264092Z","iopub.status.idle":"2024-07-04T16:46:01.333931Z","shell.execute_reply.started":"2024-07-04T16:46:01.264061Z","shell.execute_reply":"2024-07-04T16:46:01.331932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SpotifyScraper:\n    def __init__(\n        self,\n        client_id,\n        client_secret,\n#         redirect_uri,\n        scope = \"user-library-read playlist-read-private playlist-read-collaborative\",\n        delay = 0.5,\n        track_audio_feat_df = pd.DataFrame(),\n        artists_df = pd.DataFrame(),   \n        combined_df = pd.DataFrame(),\n        lyrics_audio_df = pd.DataFrame(),\n        track_video_df = pd.DataFrame(),\n        \n    ):\n        self.delay = delay\n        self.track_audio_feat_df = track_audio_feat_df\n        self.artists_df = artists_df\n        self.combined_df = combined_df\n        self.lyrics_audio_df = lyrics_audio_df\n        self.track_video_df = track_video_df\n        \n        self.yt_scraper = YTScraper()\n        self._credentials = SpotifyClientCredentials(client_id = client_id, client_secret = client_secret)\n        self.sp = Spotify(auth = self.get_access_token())\n        self.download_params = {\n            'include_audio' : True,\n            'include_lyrics' : True,\n            'output_path' : 'songs'\n        }\n            \n    def get_access_token(self):\n        # Get access token\n        access_token = self._credentials.get_access_token(as_dict = False)\n        if not access_token:\n            raise Exception(\"Access Token Not Found\")\n        return access_token\n\n    def get_auth_header(self):\n        return {\"Authorization\": \"Bearer \" + self.get_access_token()}\n    # Function to fetch user playlists\n    \n    def get_user_playlists(self):\n        print(\"Retrieving user playlists...\")\n        headers = self.get_auth_header()\n        response = requests.get(\"https://api.spotify.com/v1/me/playlists\", headers=headers)\n        response_json = response.json()\n        # for item in response_json[\"items\"]:\n        #     playlists[item[\"name\"]] = item[\"id\"]\n        print(\"Playlists retrieved successfully.\")\n        return response_json\n    \n    @staticmethod\n    def sanitize_filename(filename):\n        valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n        return ''.join(c for c in filename if c in valid_chars)\n\n    def get_track_info_by_id(self, track_id):\n        headers = self.get_auth_header()\n        response = requests.get(f\"https://api.spotify.com/v1/tracks/{track_id}\", headers=headers)\n        if not response.ok:\n            raise Exception(f\"{response.status_code} : {response.text}\")\n        response_json = response.json()\n        return response_json\n    \n    def get_playlist_info_by_id(self, playlist_id):\n        headers = self.get_auth_header()\n        response = requests.get(f\"https://api.spotify.com/v1/playlists/{playlist_id}/tracks\", headers=headers)\n        if not response.ok:\n            raise Exception(f\"{response.status_code} : {response.text}\")\n        response_json = response.json()\n        return response_json\n    \n    def get_several_track_info_by_id(self, track_ids_str, delay = 0):\n        for i in range(3):\n            headers = self.get_auth_header()\n            time.sleep(self.delay)\n            response = requests.get(f\"https://api.spotify.com/v1/tracks?ids={track_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n#                 if (retry_after):\n#                     print(f\"Retrying after {retry_after} seconds\")\n#                     time.sleep(int(retry_after) + 1)\n#                 else:\n#                     print(f\"Retrying after {retry_after} seconds\")\n#                     time.sleep(10)\n                raise Exception(f'Rate limit Hit for track_info retry after : {retry_after}')\n            else:\n                response_json = response.json()\n                return response_json\n    \n    def get_several_artist_info_by_id(self, artist_ids_str, delay = 0):\n        for i in range(3):\n            headers = self.get_auth_header()\n            time.sleep(self.delay)\n            response = requests.get(f\"https://api.spotify.com/v1/artists?ids={artist_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n#                 if (retry_after):\n#                     print(f\"Retrying after {retry_after} seconds\")\n#                     time.sleep(int(retry_after) + 1)\n#                 else:\n#                     print(f\"Retrying after {retry_after} seconds\")\n#                     time.sleep(10)\n                raise Exception(f'Rate limit Hit for artist_info retry after : {retry_after}')\n\n                  \n            else:\n                response_json = response.json()\n                return response_json\n    \n    def get_several_audio_feature_by_id(self, track_ids_str, delay = 0):\n        for i in range(3):\n            headers = self.get_auth_header()\n            time.sleep(self.delay)\n            response = requests.get(f\"https://api.spotify.com/v1/audio-features?ids={track_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n#                 if (retry_after):\n#                     print(f\"Retrying after {retry_after} seconds\")\n#                     time.sleep(int(retry_after) + 1)\n#                 else:\n#                     print(f\"Retrying after {retry_after} seconds\")\n#                     time.sleep(10)\n                raise Exception(f'Rate limit Hit for audio_feature retry after : {retry_after}')\n            else:\n                response_json = response.json()\n                return response_json\n            \n    \n    def destructure_artist_data(self,artist_obj):\n        return {\n            \"name\": artist_obj.get(\"name\"),\n            \"id\": artist_obj.get(\"id\"),\n            \"genres\": artist_obj.get(\"genres\", []),\n            \"popularity\": artist_obj.get(\"popularity\"),\n            \"followers\": artist_obj.get(\"followers\", {}).get(\"total\")\n        }\n\n        \n    def get_playlist_by_id(self,playlist_id : str):\n        return self.sp.playlist_tracks(playlist_id = playlist_id)    \n    \n    def get_relevant_artist_data(self, artist_id_list):\n            artist_slice = self.artists_df[self.artists_df['id'].isin(artist_id_list)]\n            most_popular_artist = artist_slice.loc[artist_slice['popularity'].astype(np.float64).idxmax()]\n            combined_popularity = artist_slice['popularity'].astype(np.float64).sum()\n            combined_followers = artist_slice['followers'].astype(np.float64).sum()\n            most_popular_artist_name = most_popular_artist['name']\n            combined_genres_list = artist_slice['genres'].dropna().to_list()\n            combined_genres = set([])\n            combined_genres.update(*combined_genres_list)\n            combined_genres = list(combined_genres)\n            \n            return {\n                \"popular_artist\": most_popular_artist_name,\n                \"popular_artist_id\": most_popular_artist[\"id\"],\n                \"combined_genres\": list(set(combined_genres)),\n                \"combined_popularity\" : combined_popularity,\n                \"combined_followers\" : combined_followers,\n                \"artist_popularity\": most_popular_artist[\"popularity\"],\n                \"artist_followers\": most_popular_artist[\"followers\"],\n            }\n    \n    def construct_track_and_audio_feat_dict(self,track_json = dict([]), audio_features_json = dict([])):\n        track_info = {\n            \"track_name\": track_json.get(\"name\"),\n            \"track_id\": track_json.get(\"id\"),\n            \"track_number\": track_json.get(\"track_number\"),\n            \"disc_number\": track_json.get(\"disc_number\"),\n            \"duration_ms\": track_json.get(\"duration_ms\"),\n            \"explicit\": track_json.get(\"explicit\"),\n            \"popularity\": track_json.get(\"popularity\"),\n            \"preview_url\": track_json.get(\"preview_url\"),\n            \"isrc\": track_json.get(\"external_ids\", {}).get(\"isrc\"),\n            \"album_name\": track_json.get(\"album\", {}).get(\"name\"),\n            \"album_id\": track_json.get(\"album\", {}).get(\"id\"),\n            \"album_type\": track_json.get(\"album\", {}).get(\"album_type\"),\n            \"album_total_tracks\": track_json.get(\"album\", {}).get(\"total_tracks\"),\n            \"album_release_date\": track_json.get(\"album\", {}).get(\"release_date\"),\n            \"album_release_date_precision\": track_json.get(\"album\", {}).get(\"release_date_precision\"),\n            \"album_images\": track_json.get(\"album\", {}).get(\"images\"),\n            \"artist_names\": [artist.get(\"name\") for artist in track_json.get(\"artists\", [])],\n            \"artist_ids\": [artist.get(\"id\") for artist in track_json.get(\"artists\", [])],\n            \"external_url\": track_json.get(\"external_urls\", {}).get(\"spotify\"),\n            \"acousticness\": audio_features_json.get(\"acousticness\"),\n            \"danceability\": audio_features_json.get(\"danceability\"),\n            \"energy\": audio_features_json.get(\"energy\"),\n            \"instrumentalness\": audio_features_json.get(\"instrumentalness\"),\n            \"key\": audio_features_json.get(\"key\"),\n            \"liveness\": audio_features_json.get(\"liveness\"),\n            \"loudness\": audio_features_json.get(\"loudness\"),\n            \"mode\": audio_features_json.get(\"mode\"),\n            \"speechiness\": audio_features_json.get(\"speechiness\"),\n            \"tempo\": audio_features_json.get(\"tempo\"),\n            \"time_signature\": audio_features_json.get(\"time_signature\"),\n            \"valence\": audio_features_json.get(\"valence\"),\n        }\n        return track_info\n    \n    def combine_artist_track_audiofeat(self, output_path = \"\"):\n        transformed_series = self.track_audio_feat_df['artist_ids'].apply(self.get_relevant_artist_data).to_list()\n        transformed_df = pd.DataFrame(transformed_series)\n        assert len(self.track_audio_feat_df) == len(transformed_df)\n        combined_df = pd.concat([self.track_audio_feat_df, transformed_df], axis = 1)\n        \n        SpotifyScraper.df_save_callback(combined_df,output_path,'combined_df.pkl')\n        return combined_df\n        \n    \n    @staticmethod\n    def df_save_callback(df, output_path, df_name):\n        os.makedirs(output_path, exist_ok = True)\n        df.to_pickle(os.path.join(output_path,df_name))\n        \n    @staticmethod\n    def _get_multi_threaded_data(max_workers, total_len,func,*args,message = \"\"):\n        data = []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            # List of tasks to be executed by the thread pool\n            tasks = [\n                executor.submit(func , *arg) for arg in zip(*args)\n            ]\n            success = 0\n            fails = 0\n            \n            with tqdm(total=total_len,desc=message) as pbar:\n                for future in concurrent.futures.as_completed(tasks):\n                    try:\n                        data.append(future.result())\n                        pbar.update(1)\n                        success+=1\n                    except Exception as exc:\n                        print(f'Task generated an exception: {exc}') \n                        fails+=1\n            print(f\"success : {success}, fail : {fails}\")\n                \n        return data\n    \n    def get_several_track_audio_feature(self, track_ids_list, max_workers = 50, output_path = \"\", df_name = 'track_audio_feat_df.pkl'):\n        track_id_set = set(track_ids_list)\n        if ('track_id' in self.track_audio_feat_df.columns):\n            scraped_track_ids = set(self.track_audio_feat_df['track_id'].astype(str).unique())\n            track_id_set.difference_update(scraped_track_ids)\n            \n        track_ids_list = list(track_id_set)\n        for idx in range(0,len(track_ids_list),50):\n            track_id_str = \",\".join(track_ids_list[idx:idx+50])\n            tracks_json = self.get_several_track_info_by_id(track_id_str)[\"tracks\"]\n            audio_features_json = self.get_several_audio_feature_by_id(track_ids_str=track_id_str)[\"audio_features\"]\n            temp_data = self._get_multi_threaded_data(max_workers,50,self.construct_track_and_audio_feat_dict, tracks_json, audio_features_json, message = f\"Done {idx} of {len(track_ids_list)} epoch - {idx//50}\")\n            self.track_audio_feat_df = pd.concat([self.track_audio_feat_df,pd.DataFrame(temp_data)],ignore_index = True)\n            SpotifyScraper.df_save_callback(self.track_audio_feat_df, output_path, df_name)\n    \n    def get_several_artist_features(self,artist_id_list, max_workers = 50, output_path = \"\", df_name = 'artists_df.pkl'):\n        artist_id_set = set(artist_id_list)\n        if ('id' in self.artists_df.columns):\n            scraped_artist_ids = set(self.artists_df['id'].astype(str).unique())\n            artist_id_set.difference_update(scraped_artist_ids)\n            \n        artist_id_list = list(artist_id_set)\n        for idx in range(0,len(artist_id_list),50):\n            artist_id_str = \",\".join(artist_id_list[idx:idx+50])\n            artists_json = self.get_several_artist_info_by_id(artist_id_str)[\"artists\"]\n            temp_data = self._get_multi_threaded_data(max_workers,50,self.destructure_artist_data, artists_json, message = f\"Done {idx} of {len(artist_id_list)} epoch - {idx//50}\")\n            self.artists_df = pd.concat([self.artists_df,pd.DataFrame(temp_data)],ignore_index = True)\n            SpotifyScraper.df_save_callback(self.artists_df, output_path, df_name)\n    \n    def get_video_id_str_from_track_id(self,track_id):\n        if ('track_id' not in self.combined_df.columns):\n            raise Exception(\"Please provide a dataframe to get popular_artist and track_id\")\n        try:\n            row = self.combined_df.query(f\"`track_id` == '{track_id}'\")\n            if (row.shape[0] == 0):\n                return None\n            else:\n                row = row.iloc[0]\n                track_name = row['track_name']\n                artist_name = row['popular_artist']\n                search_str = f'{track_name} {artist_name}'\n                video_id = self.yt_scraper.get_best_video_id(search_str)\n                return video_id\n        except Exception as e:\n            print(f\"error in get_video_id_str_from_track_id message : {e}\")\n            return None\n        \n    def get_track_id_video_id_mapping(self,track_ids, max_workers = 50, output_path=  './', df_name = 'track_video_df.pkl'):\n        track_video_set = set(track_ids)\n        if ('track_id' in self.track_video_df.columns):\n            scraped_track_video = set(self.track_video_df['track_id'].astype(str))\n            track_video_set.difference_update(scraped_track_video )\n        track_ids = list(track_video_set)\n        for idx in range(0,len(track_ids),50):\n            temp_data = self._get_multi_threaded_data(\n                max_workers,\n                50,\n                self.get_video_id_str_from_track_id,\n                track_ids[idx: idx+50],\n                message = f\"Video_id extraction: {idx}/{len(track_ids)} epoch : {idx//50}/{len(track_ids)//50} ||\",\n            )\n            temp_df = pd.DataFrame(zip(track_ids[idx: idx+50],temp_data), columns = ['track_id', 'video_id'])\n            temp_df.dropna(inplace = True)\n            self.track_video_df = pd.concat([self.track_video_df,temp_df],ignore_index = True)\n            SpotifyScraper.df_save_callback(self.track_video_df, output_path, df_name)\n            time.sleep(self.delay)\n            \n    def get_lyrics_from_video_id_mapping(self,video_ids, max_workes = 50, output_path=  './', df_name = 'video_lyrics_df.pkl'):\n        \n    \n    def scrap(\n        self, \n        track_ids,\n        output_path = \"\",\n        track_metadata = True, \n        audio_feat_metadata = True,\n        audio = True,\n        lyrics = True,\n    ):\n        self.get_several_track_audio_feature(\n            track_ids,\n            max_workers = 50,\n            output_path = output_path,\n        )\n        unique_artist_ids = set([])\n        unique_artist_ids.update(*self.track_audio_feat_df['artist_ids'].dropna().to_list())\n        unique_artist_ids = list(unique_artist_ids)\n        \n        self.get_several_artist_features(\n            unique_artist_ids,\n            max_workers = 50,\n            output_path = output_path,\n        )\n        \n        self.get_track_id_video_id_mapping(\n            self.combined_df['track_id'].to_list(), \n            max_workers = 50,\n            output_path = output_path,\n        )\n        \n        return self.combine_artist_track_audiofeat(output_path = output_path)\n        \n    \n    \n    def get_track_ids_from_playlist(self,*args,**kwargs):\n        playlist_data = self.sp.playlist_tracks(*args,**kwargs)\n        return [item['track']['id'] for item in playlist_data['items']]\n    \n    def get_track_ids_from_album(self,*args,**kwargs):\n        album_data = self.sp.album_tracks(*args,**kwargs)\n        return [item['id'] for item in album_data['items']]\n    \n    \n      ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:01.337238Z","iopub.execute_input":"2024-07-04T16:46:01.33771Z","iopub.status.idle":"2024-07-04T16:46:01.424815Z","shell.execute_reply.started":"2024-07-04T16:46:01.337671Z","shell.execute_reply":"2024-07-04T16:46:01.423365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Environment and Authentication","metadata":{}},{"cell_type":"markdown","source":"### Loading in Kaggle Environment","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")\nclient_id = secrets.get_secret(\"SPOTIFY_CLIENT_ID\")\nclient_secret = secrets.get_secret(\"SPOTIFY_CLIENT_SECRET\")\n# redirect_uri = secrets.get_secret(\"REDIRECT_URI\")\nyt_music_oauth_metadata = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:72.0) Gecko/20100101 Firefox/72.0\",\n    \"Accept\": \"*/*\",\n    \"Accept-Language\": \"en-US,en;q=0.5\",\n    \"Content-Type\": \"application/json\",\n    \"X-Goog-AuthUser\": \"0\",\n    \"x-origin\": \"https://music.youtube.com\",\n    \"Cookie\" : secrets.get_secret(\"YT_MUSIC_COOKIE\")\n}\n\nwith open(os.path.join('/kaggle/working/','oauth.json'), 'w') as f:\n    json.dump(yt_music_oauth_metadata, f)\n    \nwith open('/kaggle/working/tokens.json','w') as f:\n    json.dump(eval(secrets.get_secret('YT_TOKEN')), f)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:01.705064Z","iopub.execute_input":"2024-07-04T16:46:01.706188Z","iopub.status.idle":"2024-07-04T16:46:02.552517Z","shell.execute_reply.started":"2024-07-04T16:46:01.706142Z","shell.execute_reply":"2024-07-04T16:46:02.551133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scrapper Instance","metadata":{}},{"cell_type":"code","source":"!cp -r /kaggle/input/spotify-dataset/* /kaggle/working/dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:02.554809Z","iopub.execute_input":"2024-07-04T16:46:02.555225Z","iopub.status.idle":"2024-07-04T16:46:03.806004Z","shell.execute_reply.started":"2024-07-04T16:46:02.555189Z","shell.execute_reply":"2024-07-04T16:46:03.80419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conditionally_load_df(path):\n    if (os.path.exists(path)):\n        return pd.read_pickle(path)\n    else:\n        return pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:33.454493Z","iopub.execute_input":"2024-07-04T16:46:33.454985Z","iopub.status.idle":"2024-07-04T16:46:33.462176Z","shell.execute_reply.started":"2024-07-04T16:46:33.454945Z","shell.execute_reply":"2024-07-04T16:46:33.460987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scrapper = SpotifyScraper(\n    client_id=client_id,\n    client_secret=client_secret,\n#   redirect_uri=redirect_uri,\n    track_audio_feat_df=conditionally_load_df('/kaggle/working/dataset/track_audio_feat_df.pkl'),\n    artists_df=conditionally_load_df('/kaggle/working/dataset/artists_df.pkl'),\n    combined_df=conditionally_load_df('/kaggle/working/dataset/combined_df.pkl'),\n    track_video_df=conditionally_load_df('/kaggle/working/dataset/track_video_df.pkl')\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:48:43.531865Z","iopub.execute_input":"2024-07-04T16:48:43.532459Z","iopub.status.idle":"2024-07-04T16:48:46.414625Z","shell.execute_reply.started":"2024-07-04T16:48:43.532418Z","shell.execute_reply":"2024-07-04T16:48:46.413431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/spotify-metadata-audio-dataset-001/songs.json','r') as f:\n    songs_list = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:40.402985Z","iopub.execute_input":"2024-07-04T16:46:40.403419Z","iopub.status.idle":"2024-07-04T16:46:40.422806Z","shell.execute_reply.started":"2024-07-04T16:46:40.403379Z","shell.execute_reply":"2024-07-04T16:46:40.421135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"track_ids = songs_list\n# track_ids = songs_list[8400:16800] \n# track_ids = songs_list[16800:]","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:46:41.707746Z","iopub.execute_input":"2024-07-04T16:46:41.708222Z","iopub.status.idle":"2024-07-04T16:46:41.716029Z","shell.execute_reply.started":"2024-07-04T16:46:41.708184Z","shell.execute_reply":"2024-07-04T16:46:41.714306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    scrapper.scrap(track_ids, output_path = './dataset')\n    !kaggle datasets version -m \"Ishan track_video Added\" -p /kaggle/working/dataset --dir-mode tar            \nexcept:\n#     pass\n    !kaggle datasets version -m \"Ishan track_video Added\" -p /kaggle/working/dataset --dir-mode tar        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try:\n#     track_data = scrapper.get_several_track_data(\n#         track_ids[:10],\n#         parallelization=0,\n#         output_path = 'dataset/songs', \n#         include_audio = False, \n#         include_lyrics = True,\n#         max_workers = 1,\n#     )\n#     track_data_df = pd.DataFrame(track_data)\n#     track_data_df.to_pickle('dataset/total_data.pkl')\n#     scrapper.df.to_pickle('dataset/extracted_data.pkl')\n#     !kaggle datasets version -m \"Ishan 0 to 8400 metadata done\" -p /kaggle/working/dataset --dir-mode tar\n# except Exception as e:\n#     print()\n#     print(e)\n#     print()\n#     scrapper.df.to_pickle('dataset/extracted_data.pkl')\n#     !kaggle datasets version -m \"Ishan 0 to 8400 metadata salvaged\" -p /kaggle/working/dataset --dir-mode tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try:\n#     audio_output_paths  = scrapper.yt_scraper.threaded_download_song_by_video_id_list(track_data_df.video_id.to_numpy(), 'dataset/songs', max_workers = 50)\n#     audio_path_df = pd.DataFrame(audio_output_paths)\n#     track_data_df.to_pickle('dataset/total_data.pkl')\n#     scrapper.df.to_pickle('dataset/extracted_data.pkl')\n#     audio_path_df.to_pickle('total_data_audio.pkl')\n#     !kaggle datasets version -m \"Ishan 0 to 8400 audio done\" -p /kaggle/working/dataset --dir-mode tar\n# except Exception as e:\n#     print()\n#     print(e)\n#     print()\n#     audio_output_paths = scrapper.yt_scraper.threaded_download_song_by_video_id_list(scrapper.df.video_id.to_numpy(), 'dataset/songs', max_workers = 50)\n#     audio_path_df = pd.DataFrame(audio_output_paths)\n#     audio_path_df.to_pickle('extracted_data_audio.pkl')\n#     !kaggle datasets version -m \"Ishan 0 to 8400 salavge\" -p /kaggle/working/dataset --dir-mode tar    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
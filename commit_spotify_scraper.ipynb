{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8851076,"sourceType":"datasetVersion","datasetId":5315740},{"sourceId":8867981,"sourceType":"datasetVersion","datasetId":5328501,"isSourceIdPinned":true}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ishansrivastava1308/commit-notebook-of-spotify-data-scraper?scriptVersionId=187501446\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install pytube --upgrade\n!pip install spotipy\n!pip install ytmusicapi\n# !pip install yt-dlp\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\n# Suppress the specific FutureWarning\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"The behavior of DataFrame concatenation with empty or all-NA entries is deprecated.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ytmusicapi import YTMusic\nimport ytmusicapi\nfrom pytube import YouTube\nfrom spotipy.client import Spotify\nfrom spotipy import SpotifyOAuth\nfrom spotipy.oauth2 import SpotifyOauthError, SpotifyClientCredentials","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\nimport os\nimport urllib.request\nimport requests\nimport string\nimport pandas as pd\nimport numpy as np\nimport json\nimport concurrent.futures\nimport time\nimport threading\nimport traceback\nfrom pydub import AudioSegment\nfrom IPython.display import Audio\nfrom dotenv import load_dotenv\nimport multiprocessing\nfrom tqdm import tqdm\nfrom IPython.display import Audio\n# import yt_dlp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytube.innertube as pti","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pti._token_file = '/kaggle/working/tokens.json'\npti._cache_dir = '/kaggle/working'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Kaggle Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta = dict(\n    id=\"ishansrivastava1308/spotify-dataset\",\n    title=\"Spotify Dataset\",\n    isPrivate=True,\n    licenses=[dict(name=\"other\")]\n)\nos.makedirs('/kaggle/working/dataset', exist_ok = True)\nwith open(os.path.join('dataset','dataset-metadata.json'), 'w') as f:\n    json.dump(meta, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/dataset --dir-mode tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets version -m\"Added more songs and data\" -p /kaggle/working/dataset --dir-mode tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scrapper Class Definition","metadata":{}},{"cell_type":"code","source":"df_columns = ['track_name', 'track_id', 'track_number', 'disc_number', 'duration_ms',\n       'explicit', 'popularity', 'preview_url', 'isrc', 'album_name',\n       'album_id', 'album_type', 'album_total_tracks', 'album_release_date',\n       'album_release_date_precision', 'album_images', 'popular_artist',\n       'popular_artist_id', 'artist_names', 'artist_ids', 'combined_genres',\n       'artist_popularity', 'artist_followers', 'external_url', 'acousticness',\n       'danceability', 'energy', 'instrumentalness', 'key', 'liveness',\n       'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence',\n       'lyrics', 'audio_file_path', 'video_id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class YTScraper:\n    def __init__(\n        self,\n        yt_music_delay = 0.25,\n        yt_delay = 0.25,\n        token_file_path=\"oauth.json\",\n    ):\n        self.token_file_path = token_file_path\n        self.yt_music_delay = yt_music_delay\n        self.yt_delay = yt_delay\n        self.yt_lock = threading.Lock()\n        self.yt_music_lock = threading.Lock()\n        self.yt_music = YTMusic(token_file_path)\n        \n        if not os.path.exists(\"tokens.json\"):\n            YouTube(\n                \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n                use_oauth=True,\n                allow_oauth_cache=True,\n            ).streams.filter(only_audio=True).first().download()\n\n    def get_search_results(self, search_str):\n        return self.yt_music.search(search_str, filter=\"songs\")\n\n    def get_best_video_id(self, search_str):\n        search_result = self.get_search_results(search_str=search_str)\n        video_id = None\n        try:\n            for item in search_result:\n                if item[\"resultType\"] in [\"song\"] and item[\"category\"] == \"Songs\":\n                    video_id = item[\"videoId\"]\n                    break\n            return video_id\n        except Exception as e:\n            print(f\"Exception in get_best_video_id message : {e}\")\n            traceback.print_exc()\n            return video_id\n        \n\n    def get_song_from_video_id(\n        self,\n        video_id,\n        output_path=\"./\",\n        audio_format=\"mp3\",\n        target_sr=16000,\n        num_channels=1,\n    ):\n        os.makedirs(output_path, exist_ok=True)\n        temp_file = os.path.join(output_path, f\"{video_id}.mp4\")\n        download_path = os.path.join(output_path, f\"{video_id}.{audio_format}\")\n        try:\n            with self.yt_lock:\n                yt = YouTube(\n                    f\"https://youtube.com/watch?v={video_id}\",\n                    use_oauth=True,\n                    allow_oauth_cache=True,\n                )\n                video_stream = yt.streams.filter(only_audio=True).first()\n                time.sleep(self.yt_delay)\n            \n            video_stream.download(\n                output_path=output_path, filename=f\"{video_id}.mp4\"\n            )\n            if os.path.exists(temp_file):\n                #         print(f\"Downloaded successfully: {temp_file}\")\n                audio = AudioSegment.from_file(temp_file, format=\"mp4\")\n                audio = audio.set_frame_rate(target_sr)\n                audio = audio.set_channels(num_channels)\n                wav_path = f\"{temp_file[:-4] }.{audio_format}\"\n                audio.export(wav_path, format=audio_format)\n                os.remove(temp_file)\n                return download_path\n            else:\n                return None\n        except Exception as e:\n            traceback.print_exc()\n            print(f\"Exception occured in get_song_from_video_id : {e}\")\n            return None\n\n    def get_lyrics_video_id(self, video_id):\n        yt_music = YTMusic(self.token_file_path)\n        video = yt_music.get_watch_playlist(\n            videoId=video_id,\n        )\n        lyrics_id = video[\"lyrics\"]\n        lyrics = None\n        if lyrics_id:\n            lyrics = yt_music.get_lyrics(lyrics_id)\n            lyrics = lyrics[\"lyrics\"]\n        time.sleep(self.yt_music_delay)\n        return lyrics\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SpotifyScraper:\n    def __init__(\n        self,\n        client_id,\n        client_secret,\n        #         redirect_uri,\n        scope=\"user-library-read playlist-read-private playlist-read-collaborative\",\n        delay=0.5,\n        yt_music_delay=0.25,\n        yt_delay=0.25,\n        track_audio_feat_df=pd.DataFrame(),\n        artists_df=pd.DataFrame(),\n        combined_df=pd.DataFrame(),\n        lyrics_audio_df=pd.DataFrame(),\n        track_video_df=pd.DataFrame(),\n        video_lyrics_df=pd.DataFrame(),\n        audio_video_df=pd.DataFrame(),\n        verbose=False,\n    ):\n        self.delay = delay\n\n        self.track_audio_feat_df = track_audio_feat_df\n        self.artists_df = artists_df\n        self.combined_df = combined_df\n        self.lyrics_audio_df = lyrics_audio_df\n        self.track_video_df = track_video_df\n        self.video_lyrics_df = video_lyrics_df\n        self.audio_video_df = audio_video_df\n        self.verbose = verbose\n\n        self.yt_scraper = YTScraper(\n            yt_music_delay=yt_music_delay,\n            yt_delay=yt_delay,\n        )\n        self._credentials = SpotifyClientCredentials(\n            client_id=client_id, client_secret=client_secret\n        )\n        self.sp = Spotify(auth=self._get_access_token())\n\n    def _get_access_token(self):\n        # Get access token\n        access_token = self._credentials.get_access_token(as_dict=False)\n        if not access_token:\n            raise Exception(\"Access Token Not Found\")\n        return access_token\n\n    def _get_auth_header(self):\n        return {\"Authorization\": \"Bearer \" + self._get_access_token()}\n\n    def get_user_playlists(self):\n        print(\"Retrieving user playlists...\")\n        headers = self._get_auth_header()\n        response = requests.get(\n            \"https://api.spotify.com/v1/me/playlists\", headers=headers\n        )\n        response_json = response.json()\n        # for item in response_json[\"items\"]:\n        #     playlists[item[\"name\"]] = item[\"id\"]\n        print(\"Playlists retrieved successfully.\")\n        return response_json\n\n    def get_track_info_by_id(self, track_id):\n        headers = self._get_auth_header()\n        response = requests.get(\n            f\"https://api.spotify.com/v1/tracks/{track_id}\", headers=headers\n        )\n        if not response.ok:\n            raise Exception(f\"{response.status_code} : {response.text}\")\n        response_json = response.json()\n        return response_json\n\n    def get_playlist_by_id(self, playlist_id: str):\n        return self.sp.playlist_tracks(playlist_id=playlist_id)\n\n    def get_several_track_info_by_id(self, track_ids_str, delay=0):\n        for i in range(3):\n            headers = self._get_auth_header()\n            time.sleep(self.delay)\n            response = requests.get(\n                f\"https://api.spotify.com/v1/tracks?ids={track_ids_str}\",\n                headers=headers,\n            )\n            if not response.ok:\n                retry_after = response.headers.get(\"Retry-After\")\n                #                 if (retry_after):\n                #                     print(f\"Retrying after {retry_after} seconds\")\n                #                     time.sleep(int(retry_after) + 1)\n                #                 else:\n                #                     print(f\"Retrying after {retry_after} seconds\")\n                #                     time.sleep(10)\n                raise Exception(\n                    f\"Rate limit Hit for track_info retry after : {retry_after}\"\n                )\n            else:\n                response_json = response.json()\n                return response_json\n\n    def get_several_artist_info_by_id(self, artist_ids_str, delay=0):\n        for i in range(3):\n            headers = self._get_auth_header()\n            time.sleep(self.delay)\n            response = requests.get(\n                f\"https://api.spotify.com/v1/artists?ids={artist_ids_str}\",\n                headers=headers,\n            )\n            if not response.ok:\n                retry_after = response.headers.get(\"Retry-After\")\n                #                 if (retry_after):\n                #                     print(f\"Retrying after {retry_after} seconds\")\n                #                     time.sleep(int(retry_after) + 1)\n                #                 else:\n                #                     print(f\"Retrying after {retry_after} seconds\")\n                #                     time.sleep(10)\n                raise Exception(\n                    f\"Rate limit Hit for artist_info retry after : {retry_after}\"\n                )\n\n            else:\n                response_json = response.json()\n                return response_json\n\n    def get_several_audio_feature_by_id(self, track_ids_str, delay=0):\n        for i in range(3):\n            headers = self._get_auth_header()\n            time.sleep(self.delay)\n            response = requests.get(\n                f\"https://api.spotify.com/v1/audio-features?ids={track_ids_str}\",\n                headers=headers,\n            )\n            if not response.ok:\n                retry_after = response.headers.get(\"Retry-After\")\n                #                 if (retry_after):\n                #                     print(f\"Retrying after {retry_after} seconds\")\n                #                     time.sleep(int(retry_after) + 1)\n                #                 else:\n                #                     print(f\"Retrying after {retry_after} seconds\")\n                #                     time.sleep(10)\n                raise Exception(\n                    f\"Rate limit Hit for audio_feature retry after : {retry_after}\"\n                )\n            else:\n                response_json = response.json()\n                return response_json\n\n    def _destructure_artist_data(self, artist_obj):\n        return {\n            \"name\": artist_obj.get(\"name\"),\n            \"id\": artist_obj.get(\"id\"),\n            \"genres\": artist_obj.get(\"genres\", []),\n            \"popularity\": artist_obj.get(\"popularity\"),\n            \"followers\": artist_obj.get(\"followers\", {}).get(\"total\"),\n        }\n\n    def _get_relevant_artist_data(self, artist_id_list):\n        artist_slice = self.artists_df[self.artists_df[\"id\"].isin(artist_id_list)]\n        most_popular_artist = artist_slice.loc[\n            artist_slice[\"popularity\"].astype(np.float64).idxmax()\n        ]\n        combined_popularity = artist_slice[\"popularity\"].astype(np.float64).sum()\n        combined_followers = artist_slice[\"followers\"].astype(np.float64).sum()\n        most_popular_artist_name = most_popular_artist[\"name\"]\n        combined_genres_list = artist_slice[\"genres\"].dropna().to_list()\n        combined_genres = set([])\n        combined_genres.update(*combined_genres_list)\n        combined_genres = list(combined_genres)\n\n        return {\n            \"popular_artist\": most_popular_artist_name,\n            \"popular_artist_id\": most_popular_artist[\"id\"],\n            \"combined_genres\": list(set(combined_genres)),\n            \"combined_popularity\": combined_popularity,\n            \"combined_followers\": combined_followers,\n            \"artist_popularity\": most_popular_artist[\"popularity\"],\n            \"artist_followers\": most_popular_artist[\"followers\"],\n        }\n\n    def _construct_track_and_audio_feat_dict(\n        self, track_json=dict([]), audio_features_json=dict([])\n    ):\n        track_info = {\n            \"track_name\": track_json.get(\"name\"),\n            \"track_id\": track_json.get(\"id\"),\n            \"track_number\": track_json.get(\"track_number\"),\n            \"disc_number\": track_json.get(\"disc_number\"),\n            \"duration_ms\": track_json.get(\"duration_ms\"),\n            \"explicit\": track_json.get(\"explicit\"),\n            \"popularity\": track_json.get(\"popularity\"),\n            \"preview_url\": track_json.get(\"preview_url\"),\n            \"isrc\": track_json.get(\"external_ids\", {}).get(\"isrc\"),\n            \"album_name\": track_json.get(\"album\", {}).get(\"name\"),\n            \"album_id\": track_json.get(\"album\", {}).get(\"id\"),\n            \"album_type\": track_json.get(\"album\", {}).get(\"album_type\"),\n            \"album_total_tracks\": track_json.get(\"album\", {}).get(\"total_tracks\"),\n            \"album_release_date\": track_json.get(\"album\", {}).get(\"release_date\"),\n            \"album_release_date_precision\": track_json.get(\"album\", {}).get(\n                \"release_date_precision\"\n            ),\n            \"album_images\": track_json.get(\"album\", {}).get(\"images\"),\n            \"artist_names\": [\n                artist.get(\"name\") for artist in track_json.get(\"artists\", [])\n            ],\n            \"artist_ids\": [\n                artist.get(\"id\") for artist in track_json.get(\"artists\", [])\n            ],\n            \"external_url\": track_json.get(\"external_urls\", {}).get(\"spotify\"),\n            \"acousticness\": audio_features_json.get(\"acousticness\"),\n            \"danceability\": audio_features_json.get(\"danceability\"),\n            \"energy\": audio_features_json.get(\"energy\"),\n            \"instrumentalness\": audio_features_json.get(\"instrumentalness\"),\n            \"key\": audio_features_json.get(\"key\"),\n            \"liveness\": audio_features_json.get(\"liveness\"),\n            \"loudness\": audio_features_json.get(\"loudness\"),\n            \"mode\": audio_features_json.get(\"mode\"),\n            \"speechiness\": audio_features_json.get(\"speechiness\"),\n            \"tempo\": audio_features_json.get(\"tempo\"),\n            \"time_signature\": audio_features_json.get(\"time_signature\"),\n            \"valence\": audio_features_json.get(\"valence\"),\n        }\n        return track_info\n\n    @staticmethod\n    def _df_save_callback(df, output_path, df_name):\n        os.makedirs(output_path, exist_ok=True)\n        df.to_pickle(os.path.join(output_path, df_name))\n\n    def _get_video_id_str_from_track_id(self, track_id):\n        if \"track_id\" not in self.combined_df.columns:\n            raise Exception(\n                \"Please provide a dataframe to get popular_artist and track_id\"\n            )\n        try:\n            row = self.combined_df.query(f\"`track_id` == '{track_id}'\")\n            if row.shape[0] == 0:\n                return None\n            else:\n                row = row.iloc[0]\n                track_name = row[\"track_name\"]\n                artist_name = row[\"popular_artist\"]\n                search_str = f\"{track_name} {artist_name}\"\n                video_id = self.yt_scraper.get_best_video_id(search_str)\n                return video_id\n        except Exception as e:\n            print(f\"error in _get_video_id_str_from_track_id message : {e}\")\n            return None\n\n    @staticmethod\n    def _get_multi_threaded_data(\n        max_workers,\n        total_len,\n        func,\n        task_args=[],\n        return_None=False,\n        None_return_val=None,\n        message=\"\",\n        verbose=False,\n    ):\n        data = []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            # List of tasks to be executed by the thread pool\n            tasks = [executor.submit(func, *arg) for arg in task_args]\n            success = 0\n            fails = 0\n\n            with tqdm(total=total_len, desc=message) as pbar:\n                for future in tasks:\n                    try:\n                        data.append(future.result())\n                        pbar.update(1)\n                        success += 1\n                        if verbose:\n                            print()\n                    except Exception as exc:\n                        print(f\"Task generated an exception: {exc}\")\n                        if return_None:\n                            data.append(None_return_val)\n                        fails += 1\n\n            print(f\"success : {success}, fail : {fails}\")\n\n        return data\n\n    def combine_artist_track_audiofeat(self, max_workers=50, output_path=\"\"):\n        transformed_series = self._get_multi_threaded_data(\n            max_workers,\n            len(self.track_audio_feat_df[\"artist_ids\"]),\n            self._get_relevant_artist_data,\n            task_args=zip(self.track_audio_feat_df[\"artist_ids\"].to_list()),\n            return_None=True,\n            None_return_val={\n                \"popular_artist\": None,\n                \"popular_artist_id\": None,\n                \"combined_genres\": [],\n                \"combined_popularity\": None,\n                \"combined_followers\": None,\n                \"artist_popularity\": None,\n                \"artist_followers\": None,\n            },\n            message=\"Combining Knowledge from tracks and artist : \",\n        )\n        transformed_df = pd.DataFrame(transformed_series)\n        assert len(self.track_audio_feat_df) == len(transformed_df)\n        self.combined_df = pd.concat([self.track_audio_feat_df, transformed_df], axis=1)\n\n        SpotifyScraper._df_save_callback(\n            self.combined_df, output_path, \"combined_df.pkl\"\n        )\n\n    def get_several_track_audio_feature(\n        self,\n        track_ids_list,\n        max_workers=50,\n        output_path=\"\",\n        df_name=\"track_audio_feat_df.pkl\",\n    ):\n        track_id_set = set(track_ids_list)\n        if \"track_id\" in self.track_audio_feat_df.columns:\n            scraped_track_ids = set(\n                self.track_audio_feat_df[\"track_id\"].astype(str).unique()\n            )\n            track_id_set.difference_update(scraped_track_ids)\n\n        track_ids_list = list(track_id_set)\n        for idx in range(0, len(track_ids_list), 50):\n            track_id_str = \",\".join(track_ids_list[idx : idx + 50])\n            tracks_json = self.get_several_track_info_by_id(track_id_str)[\"tracks\"]\n            audio_features_json = self.get_several_audio_feature_by_id(\n                track_ids_str=track_id_str\n            )[\"audio_features\"]\n            temp_data = self._get_multi_threaded_data(\n                max_workers,\n                50,\n                self._construct_track_and_audio_feat_dict,\n                task_args=zip(\n                    tracks_json,\n                    audio_features_json,\n                ),\n                verbose=self.verbose,\n                message=f\"Done {idx} of {len(track_ids_list)} epoch - {idx//50}\",\n            )\n            self.track_audio_feat_df = pd.concat(\n                [self.track_audio_feat_df, pd.DataFrame(temp_data)], ignore_index=True\n            )\n            SpotifyScraper._df_save_callback(\n                self.track_audio_feat_df, output_path, df_name\n            )\n\n    def get_several_artist_features(\n        self, artist_id_list, max_workers=50, output_path=\"\", df_name=\"artists_df.pkl\"\n    ):\n        artist_id_set = set(artist_id_list)\n        if \"id\" in self.artists_df.columns:\n            scraped_artist_ids = set(self.artists_df[\"id\"].astype(str).unique())\n            artist_id_set.difference_update(scraped_artist_ids)\n\n        artist_id_list = list(artist_id_set)\n        for idx in range(0, len(artist_id_list), 50):\n            artist_id_str = \",\".join(artist_id_list[idx : idx + 50])\n            artists_json = self.get_several_artist_info_by_id(artist_id_str)[\"artists\"]\n            temp_data = self._get_multi_threaded_data(\n                max_workers,\n                50,\n                self._destructure_artist_data,\n                task_args=zip(artists_json),\n                verbose=self.verbose,\n                message=f\"Done {idx} of {len(artist_id_list)} epoch - {idx//50}\",\n            )\n            self.artists_df = pd.concat(\n                [self.artists_df, pd.DataFrame(temp_data)], ignore_index=True\n            )\n            SpotifyScraper._df_save_callback(self.artists_df, output_path, df_name)\n\n    def get_track_id_video_id_mapping(\n        self, track_ids, max_workers=50, output_path=\"./\", df_name=\"track_video_df.pkl\"\n    ):\n        track_video_set = set(track_ids)\n        if \"track_id\" in self.track_video_df.columns:\n            scraped_track_video = set(self.track_video_df[\"track_id\"].astype(str))\n            track_video_set.difference_update(scraped_track_video)\n        track_ids = list(track_video_set)\n        for idx in range(0, len(track_ids), 50):\n            current_track_ids = track_ids[idx : idx + 50]\n            temp_data = self._get_multi_threaded_data(\n                max_workers,\n                len(current_track_ids),\n                self._get_video_id_str_from_track_id,\n                task_args=zip(current_track_ids),\n                verbose=self.verbose,\n                message=f\"Video_id extraction: {idx}/{len(track_ids)} epoch : {idx//50}/{len(track_ids)//50} ||\",\n                return_None=True,\n                None_return_val=None,\n            )\n            assert len(temp_data) == len(current_track_ids)\n            temp_df = pd.DataFrame(\n                zip(current_track_ids, temp_data),\n                columns=[\"track_id\", \"video_id\"],\n            )\n            temp_df.dropna(inplace=True)\n            self.track_video_df = pd.concat(\n                [self.track_video_df, temp_df], ignore_index=True\n            )\n            SpotifyScraper._df_save_callback(self.track_video_df, output_path, df_name)\n\n    def get_lyrics_from_video_id_mapping(\n        self, video_ids, max_workers=50, output_path=\"./\", df_name=\"video_lyrics_df.pkl\"\n    ):\n        id_set = set(video_ids)\n        if \"video_id\" in self.video_lyrics_df.columns:\n            scrapped_ids = set(self.video_lyrics_df[\"video_id\"].astype(str))\n            id_set.difference_update(scrapped_ids)\n        video_ids = list(id_set)\n\n        for idx in range(0, len(video_ids), 50):\n            current_video_ids = video_ids[idx : idx + 50]\n            temp_data = self._get_multi_threaded_data(\n                max_workers,\n                len(current_video_ids),\n                self.yt_scraper.get_lyrics_video_id,\n                task_args=zip(current_video_ids),\n                verbose=self.verbose,\n                message=f\"Lyrics extraction: {idx}/{len(video_ids)} epoch : {idx//50}/{len(video_ids)//50} ||\",\n                return_None=True,\n                None_return_val=None,\n            )\n            assert len(temp_data) == len(current_video_ids)\n            temp_df = pd.DataFrame(\n                zip(current_video_ids, temp_data),\n                columns=[\"video_id\", \"lyrics\"],\n            )\n            temp_df.dropna(inplace=True)\n            self.video_lyrics_df = pd.concat(\n                [self.video_lyrics_df, temp_df], ignore_index=True\n            )\n            SpotifyScraper._df_save_callback(self.video_lyrics_df, output_path, df_name)\n\n    def get_audio_from_video_id_mapping(\n        self,\n        video_ids,\n        max_workers=50,\n        output_path=\"./\",\n        df_name=\"audio_video_df.pkl\",\n        audio_output_path=\"./songs\",\n        audio_format=\"mp3\",\n    ):\n        id_set = set(video_ids)\n        if \"video_id\" in self.audio_video_df.columns:\n            scrapped_ids = set(self.audio_video_df[\"video_id\"].astype(str).dropna())\n            id_set.difference_update(scrapped_ids)\n        video_ids = list(id_set)\n\n        for idx in range(0, len(video_ids), 50):\n            current_video_ids = video_ids[idx : idx + 50]\n            audio_output_path_arg = [audio_output_path] * len(current_video_ids)\n            format_arg = [audio_format] * len(current_video_ids)\n\n            temp_data = self._get_multi_threaded_data(\n                max_workers,\n                len(current_video_ids),\n                self.yt_scraper.get_song_from_video_id,\n                task_args=zip(\n                    current_video_ids,\n                    audio_output_path_arg,\n                    format_arg,\n                ),\n                verbose=self.verbose,\n                message=f\"Audio extraction: {idx}/{len(video_ids)} epoch : {idx//50}/{len(video_ids)//50} ||\",\n                return_None=True,\n                None_return_val=None,\n            )\n            assert len(temp_data) == len(current_video_ids)\n            temp_df = pd.DataFrame(\n                zip(video_ids[idx : idx + 50], temp_data),\n                columns=[\"video_id\", \"audio_file_path\"],\n            )\n            temp_df.dropna(inplace=True)\n            self.audio_video_df = pd.concat(\n                [self.audio_video_df, temp_df], ignore_index=True\n            )\n            SpotifyScraper._df_save_callback(self.audio_video_df, output_path, df_name)\n\n    def scrap(\n        self,\n        track_ids,\n        output_path=\"./\",\n        audio_output_path=\"./songs\",\n        audio=True,\n        lyrics=True,\n    ):\n        self.get_several_track_audio_feature(\n            track_ids,\n            max_workers=50,\n            output_path=output_path,\n        )\n\n        print(\"\\nExtracted Track Data\\n\")\n\n        unique_artist_ids = set([])\n        unique_artist_ids.update(\n            *self.track_audio_feat_df[\"artist_ids\"].dropna().to_list()\n        )\n        unique_artist_ids = list(unique_artist_ids)\n\n        self.get_several_artist_features(\n            unique_artist_ids,\n            max_workers=50,\n            output_path=output_path,\n        )\n\n        print(\"\\nExtracted Artist Data\\n\")\n\n        self.combine_artist_track_audiofeat(max_workers=50,output_path=output_path)\n        print(\"\\Combined track and artist Data\\n\")\n\n        self.get_track_id_video_id_mapping(\n            track_ids,\n            max_workers=50,\n            output_path=output_path,\n        )\n        print(\"\\nExtracted video_id Data\\n\")\n\n        video_id_list = self.track_video_df[\n            self.track_video_df[\"track_id\"].isin(track_ids)\n        ][\"video_id\"].to_list()\n\n        if lyrics:\n            self.get_lyrics_from_video_id_mapping(\n                video_id_list,\n                max_workers=50,\n                output_path=output_path,\n            )\n            print(\"\\nExtracted lyrics Data\\n\")\n        if audio:\n            self.get_audio_from_video_id_mapping(\n                video_id_list,\n                max_workers=50,\n                output_path=output_path,\n                audio_output_path=audio_output_path,\n            )\n            print(\"\\nExtracted audio Data\\n\")\n        print(\"Merging all the data\")\n        self.get_merged_df(output_path = output_path)\n        print(\"\\nExtracted all Data\\n\")\n        \n        \n\n    def get_track_ids_from_playlist(\n        self,\n        playlist_id,\n        only_ids=True,\n        fields=None,\n        limit=100,\n        offset=0,\n        market=None,\n        additional_types=(\"track\",),\n    ):\n        playlist_data = self.sp.playlist_tracks(\n            playlist_id=playlist_id,\n            fields=fields,\n            limit=limit,\n            offset=offset,\n            market=market,\n            additional_types=additional_types,\n        )\n        if only_ids:\n            return [item[\"track\"][\"id\"] for item in playlist_data[\"items\"]]\n        else:\n            return playlist_data\n\n    def get_track_ids_from_album(\n        self, album_id, only_ids=True, limit=50, offset=0, market=None\n    ):\n        album_data = self.sp.album_tracks(album_id, limit=50, offset=0, market=None)\n        if only_ids:\n            return [item[\"id\"] for item in album_data[\"items\"]]\n        else:\n            return album_data\n    \n    def get_merged_df(self, output_path = \"./\", df_name = \"full_df.pkl\"):\n        self.full_df = self.combined_df.merge(\n            self.track_video_df,\n            on = 'track_id',\n            how = 'left',\n        ).merge(\n            self.video_lyrics_df,\n            on = 'video_id',\n            how = 'left',\n        ).merge(\n            self.audio_video_df,\n            on = 'video_id',\n            how = 'left'\n        )\n        self._df_save_callback(self.full_df,output_path, df_name)\n        return self.full_df","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Environment and Authentication","metadata":{}},{"cell_type":"markdown","source":"### Loading in Kaggle Environment","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")\nclient_id = secrets.get_secret(\"SPOTIFY_CLIENT_ID\")\nclient_secret = secrets.get_secret(\"SPOTIFY_CLIENT_SECRET\")\n# redirect_uri = secrets.get_secret(\"REDIRECT_URI\")\nyt_music_oauth_metadata = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:72.0) Gecko/20100101 Firefox/72.0\",\n    \"Accept\": \"*/*\",\n    \"Accept-Language\": \"en-US,en;q=0.5\",\n    \"Content-Type\": \"application/json\",\n    \"X-Goog-AuthUser\": \"0\",\n    \"x-origin\": \"https://music.youtube.com\",\n    \"Cookie\" : secrets.get_secret(\"YT_MUSIC_COOKIE\")\n}\n\nwith open(os.path.join('/kaggle/working/','oauth.json'), 'w') as f:\n    json.dump(yt_music_oauth_metadata, f)\n    \nwith open('/kaggle/working/tokens.json','w') as f:\n    json.dump(eval(secrets.get_secret('YT_TOKEN')), f)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scrapper Instance","metadata":{}},{"cell_type":"code","source":"# !rm -r /kaggle/working/dataset/*\n!cp -r /kaggle/input/spotify-dataset/* /kaggle/working/dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dataset_path = './dataset'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conditionally_load_df(path , return_new = False, columns = []):\n    if (os.path.exists(path)) and not return_new:\n        return pd.read_pickle(path)\n    else:\n        return pd.DataFrame(columns=columns)\n\nparams = {\n    'track_audio_feat_df' : conditionally_load_df(\n        path = os.path.join(base_dataset_path,'track_audio_feat_df.pkl'),\n        return_new = False,\n        columns = []\n    ),\n    'artists_df' : conditionally_load_df(\n        path = os.path.join(base_dataset_path,'artists_df.pkl'),\n        return_new = False,\n        columns = []\n    ),\n    'combined_df' : conditionally_load_df(\n        path = os.path.join(base_dataset_path,'combined_df.pkl'), \n        return_new = False,\n        columns = []\n    ),\n    'track_video_df' : conditionally_load_df(\n        path = os.path.join(base_dataset_path,'track_video_df.pkl'), \n        return_new = False,\n        columns = ['track_id','video_id']\n    ),\n    'video_lyrics_df' : conditionally_load_df(\n        path = os.path.join(base_dataset_path,'video_lyrics_df.pkl'), \n        return_new = False,\n        columns = ['video_id','lyrics']\n    ),\n    'audio_video_df' : conditionally_load_df(\n        path = os.path.join(base_dataset_path,'audio_video_df.pkl'),\n        return_new = False,\n        columns = ['video_id','audio_file_path']\n    ),\n}","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scrapper = SpotifyScraper(\n    client_id=client_id,\n    client_secret=client_secret,\n#   redirect_uri=redirect_uri,\n    yt_delay = 0.1,\n    yt_music_delay=0,\n    delay = 0.5,\n    verbose = False,\n    **params,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/spotify-metadata-audio-dataset-001/songs.json','r') as f:\n    songs_list = json.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"track_ids = songs_list\n# track_ids = songs_list[8400:16800] \n# track_ids = songs_list[16800:]\nprint(len(track_ids))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    scrapper.scrap(\n        track_ids, \n        audio = False, \n        output_path = base_dataset_path,\n        audio_output_path=os.path.join(base_dataset_path,'songs')\n    )\n\n    !kaggle datasets version -m \"Ishan More Data Added\" -p /kaggle/working/dataset --dir-mode tar            \nexcept:\n#     pass\n    !kaggle datasets version -m \"Ishan track_video Added\" -p /kaggle/working/dataset --dir-mode tar        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
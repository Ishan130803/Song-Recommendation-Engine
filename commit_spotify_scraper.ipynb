{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8851076,"sourceType":"datasetVersion","datasetId":5315740}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ishansrivastava1308/commit-notebook-of-spotify-data-scraper?scriptVersionId=186730139\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install pytube --upgrade\n!pip install spotipy\n!pip install ytmusicapi\n# !pip install yt-dlp\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ytmusicapi import YTMusic\nimport ytmusicapi\nfrom pprint import pprint\nimport os\nfrom pytube import YouTube\nimport urllib.request\nimport requests\nimport string\nfrom spotipy.client import Spotify\nfrom spotipy import SpotifyOAuth\nfrom spotipy.oauth2 import SpotifyOauthError, SpotifyClientCredentials\nimport pandas as pd\nimport numpy as np\nimport json\nimport concurrent.futures\nimport time\nimport threading\nfrom pydub import AudioSegment\nfrom IPython.display import Audio\nfrom dotenv import load_dotenv\nimport multiprocessing\nfrom tqdm import tqdm\nfrom IPython.display import Audio\n# import yt_dlp","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:21.170179Z","iopub.execute_input":"2024-07-03T18:55:21.170609Z","iopub.status.idle":"2024-07-03T18:55:21.177831Z","shell.execute_reply.started":"2024-07-03T18:55:21.170575Z","shell.execute_reply":"2024-07-03T18:55:21.176607Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"import pytube.innertube as pti","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:25.67481Z","iopub.execute_input":"2024-07-03T18:55:25.675888Z","iopub.status.idle":"2024-07-03T18:55:25.680162Z","shell.execute_reply.started":"2024-07-03T18:55:25.675842Z","shell.execute_reply":"2024-07-03T18:55:25.679116Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"pti._token_file = '/kaggle/working/tokens.json'\npti._cache_dir = '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:25.865684Z","iopub.execute_input":"2024-07-03T18:55:25.866107Z","iopub.status.idle":"2024-07-03T18:55:25.870872Z","shell.execute_reply.started":"2024-07-03T18:55:25.866073Z","shell.execute_reply":"2024-07-03T18:55:25.869734Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"markdown","source":"# Making Kaggle Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:26.154995Z","iopub.execute_input":"2024-07-03T18:55:26.155387Z","iopub.status.idle":"2024-07-03T18:55:26.741191Z","shell.execute_reply.started":"2024-07-03T18:55:26.155356Z","shell.execute_reply":"2024-07-03T18:55:26.740274Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"meta = dict(\n    id=\"ishansrivastava1308/spotify-dataset\",\n    title=\"Spotify Dataset\",\n    isPrivate=True,\n    licenses=[dict(name=\"other\")]\n)\nos.makedirs('/kaggle/working/dataset', exist_ok = True)\nwith open(os.path.join('dataset','dataset-metadata.json'), 'w') as f:\n    json.dump(meta, f)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:26.743076Z","iopub.execute_input":"2024-07-03T18:55:26.743535Z","iopub.status.idle":"2024-07-03T18:55:26.751289Z","shell.execute_reply.started":"2024-07-03T18:55:26.743498Z","shell.execute_reply":"2024-07-03T18:55:26.750132Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets create -p /kaggle/working/dataset --dir-mode tar","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:26.752598Z","iopub.execute_input":"2024-07-03T18:55:26.752913Z","iopub.status.idle":"2024-07-03T18:55:26.76137Z","shell.execute_reply.started":"2024-07-03T18:55:26.752887Z","shell.execute_reply":"2024-07-03T18:55:26.760437Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets version -m\"Added more songs and data\" -p /kaggle/working/dataset --dir-mode tar","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:26.850284Z","iopub.execute_input":"2024-07-03T18:55:26.850675Z","iopub.status.idle":"2024-07-03T18:55:26.855248Z","shell.execute_reply.started":"2024-07-03T18:55:26.850646Z","shell.execute_reply":"2024-07-03T18:55:26.854118Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"# Scrapper Class Definition","metadata":{}},{"cell_type":"code","source":"df_columns = ['track_name', 'track_id', 'track_number', 'disc_number', 'duration_ms',\n       'explicit', 'popularity', 'preview_url', 'isrc', 'album_name',\n       'album_id', 'album_type', 'album_total_tracks', 'album_release_date',\n       'album_release_date_precision', 'album_images', 'popular_artist',\n       'popular_artist_id', 'artist_names', 'artist_ids', 'combined_genres',\n       'artist_popularity', 'artist_followers', 'external_url', 'acousticness',\n       'danceability', 'energy', 'instrumentalness', 'key', 'liveness',\n       'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence',\n       'lyrics', 'audio_file_path', 'video_id']","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:27.340263Z","iopub.execute_input":"2024-07-03T18:55:27.340635Z","iopub.status.idle":"2024-07-03T18:55:27.346434Z","shell.execute_reply.started":"2024-07-03T18:55:27.340604Z","shell.execute_reply":"2024-07-03T18:55:27.345277Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"class YTScraper:\n    def __init__(\n        self,\n        token_file_path=\"oauth.json\",\n    ):\n        self.yt_music = YTMusic(token_file_path)\n        YouTube(\n            \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n            use_oauth=True,\n            allow_oauth_cache=True,\n        ).streams.filter(only_audio=True).first().download()\n\n    def get_search_results(self, search_str):\n        return self.yt_music.search(search_str, filter=\"songs\")\n\n    def get_lyrics(self, video_id):\n        video = self.yt_music.get_watch_playlist(\n            videoId=video_id,\n        )\n        lyrics_id = video[\"lyrics\"]\n        lyrics = None\n        if lyrics_id:\n            lyrics = self.yt_music.get_lyrics(lyrics_id)\n        return lyrics\n\n    #   def download_song_by_video_id(\n    #         self,\n    #         video_id,\n    #         output_path=None,\n    #         audio_format = 'mp3'\n    #   ):\n    #         if output_path is not None:\n    #             os.makedirs(output_path,exist_ok=True)\n    #         else:\n    #             output_path = \"\"\n    #         ydl_opts = {\n    #             'format': 'm4a/bestaudio/best',\n    #             # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n    #             'postprocessors': [{  # Extract audio using ffmpeg\n    #                 'key': 'FFmpegExtractAudio',\n    #                 'preferredcodec': 'mp3',\n    #             }]\n    #         }\n\n    #         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n    #             error_code = ydl.download()\n\n    def download_song_by_video_id(\n        self,\n        video_id,\n        output_path=None,\n    ):\n        if output_path is not None:\n            os.makedirs(output_path, exist_ok=True)\n        else:\n            output_path = \"\"\n        yt = YouTube(f\"https://youtube.com/watch?v={video_id}\")\n        temp_file = os.path.join(output_path, f\"{video_id}.mp4\")\n        yt.streams.filter(only_audio=True).first().download(\n            output_path=output_path, filename=f\"{video_id}.mp4\"\n        )\n        if os.path.exists(temp_file):\n            #         print(f\"Downloaded successfully: {temp_file}\")\n            audio = AudioSegment.from_file(temp_file, format=\"mp4\")\n            audio = audio.set_frame_rate(16000)\n            audio = audio.set_channels(1)\n            wav_path = temp_file[:-4] + \".mp3\"\n            audio.export(wav_path, format=\"mp3\")\n            os.remove(temp_file)\n\n        return os.path.join(output_path, f\"{video_id}.mp3\")\n\n    def threaded_download_song_by_video_id_list(\n        self, video_id_list, output_path=\"songs\", max_workers=50\n    ):\n        data = []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            # List of tasks to be executed by the thread pool\n            output_path_args = [output_path] * len(video_id_list)\n            tasks = [\n                executor.submit(self.download_song_by_video_id, *args)\n                for args in zip(video_id_list, output_path_args)\n            ]\n            success = 0\n            fails = 0\n\n            with tqdm(total=len(video_id_list)) as pbar:\n                for future in concurrent.futures.as_completed(tasks):\n                    try:\n                        data.append(future.result())\n                        pbar.update(1)\n                        success += 1\n                    except Exception as exc:\n                        print(f\"Task generated an exception: {exc}\")\n                        fails += 1\n            print({\"success\": success, \"fail\": fails})\n        return np.array(data)\n\n    def scrap_by_search(\n        self,\n        search_str,\n        download_params={\n            \"include_audio\": True,\n            \"include_lyrics\": True,\n            \"output_path\": \"songs\",\n        },\n    ):\n        include_lyrics = download_params[\"include_lyrics\"]\n        include_audio = download_params[\"include_audio\"]\n        output_path = download_params[\"output_path\"]\n\n        search_result = self.get_search_results(search_str=search_str)\n        video_id = None\n        for item in search_result:\n            if item[\"resultType\"] in [\"song\"] and item[\"category\"] == \"Songs\":\n                video_id = item[\"videoId\"]\n                break\n        lyrics = {\"lyrics\": None, \"source\": None}\n        download_path = None\n        if video_id:\n            if include_lyrics:\n                lyrics = self.get_lyrics(video_id=video_id)\n                if not lyrics:\n                    lyrics = {\"lyrics\": None, \"source\": None}\n            if include_audio:\n                download_path = self.download_song_by_video_id(\n                    video_id=video_id, output_path=output_path\n                )\n\n        return {\n            \"lyrics\": lyrics[\"lyrics\"],\n            \"audio_file_path\": download_path,\n            \"video_id\": video_id,\n        }","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:27.572143Z","iopub.execute_input":"2024-07-03T18:55:27.572547Z","iopub.status.idle":"2024-07-03T18:55:27.5928Z","shell.execute_reply.started":"2024-07-03T18:55:27.572513Z","shell.execute_reply":"2024-07-03T18:55:27.591543Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"class SpotifyScraper:\n    def __init__(\n        self,\n        client_id,\n        client_secret,\n#         redirect_uri,\n        scope = \"user-library-read playlist-read-private playlist-read-collaborative\"\n        \n    ):\n        self.df = pd.DataFrame(columns = df_columns)\n        self.yt_scraper = YTScraper()\n        self._credentials = SpotifyClientCredentials(client_id = client_id, client_secret = client_secret)\n        self.sp = Spotify(auth = self.get_access_token())\n        self.download_params = {\n            'include_audio' : True,\n            'include_lyrics' : True,\n            'output_path' : 'songs'\n        }\n            \n    def get_access_token(self):\n        # Get access token\n        access_token = self._credentials.get_access_token(as_dict = False)\n        if not access_token:\n            raise Exception(\"Access Token Not Found\")\n        return access_token\n\n    def get_auth_header(self):\n        return {\"Authorization\": \"Bearer \" + self.get_access_token()}\n    # Function to fetch user playlists\n    \n    def get_user_playlists(self):\n        print(\"Retrieving user playlists...\")\n        headers = self.get_auth_header()\n        response = requests.get(\"https://api.spotify.com/v1/me/playlists\", headers=headers)\n        response_json = response.json()\n        # for item in response_json[\"items\"]:\n        #     playlists[item[\"name\"]] = item[\"id\"]\n        print(\"Playlists retrieved successfully.\")\n        return response_json\n    \n    @staticmethod\n    def sanitize_filename(filename):\n        valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n        return ''.join(c for c in filename if c in valid_chars)\n\n    def get_track_info_by_id(self, track_id):\n        headers = self.get_auth_header()\n        response = requests.get(f\"https://api.spotify.com/v1/tracks/{track_id}\", headers=headers)\n        if not response.ok:\n            raise Exception(f\"{response.status_code} : {response.text}\")\n        response_json = response.json()\n        return response_json\n    \n    def get_playlist_info_by_id(self, playlist_id):\n        headers = self.get_auth_header()\n        response = requests.get(f\"https://api.spotify.com/v1/playlists/{playlist_id}/tracks\", headers=headers)\n        if not response.ok:\n            raise Exception(f\"{response.status_code} : {response.text}\")\n        response_json = response.json()\n        return response_json\n    \n    def get_several_track_info_by_id(self, track_ids_str):\n        for i in range(3):\n            headers = self.get_auth_header()\n            response = requests.get(f\"https://api.spotify.com/v1/tracks?ids={track_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n                if (retry_after):\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(int(retry_after) + 1)\n                else:\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(10)\n            else:\n                response_json = response.json()\n                return response_json\n    \n    def get_several_artist_info_by_id(self, artist_ids_str):\n        for i in range(3):\n            headers = self.get_auth_header()\n            response = requests.get(f\"https://api.spotify.com/v1/artists?ids={artist_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n                if (retry_after):\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(int(retry_after) + 1)\n                else:\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(10)\n            else:\n                response_json = response.json()\n                return response_json\n    \n    def get_several_audio_feature_by_id(self, track_ids_str):\n        for i in range(3):\n            headers = self.get_auth_header()\n            response = requests.get(f\"https://api.spotify.com/v1/audio-features?ids={track_ids_str}\", headers=headers)\n            if not response.ok:\n                retry_after = response.headers.get('Retry-After')\n                if (retry_after):\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(int(retry_after) + 1)\n                else:\n                    print(f\"Retrying after {retry_after} seconds\")\n                    time.sleep(10)\n            else:\n                response_json = response.json()\n                return response_json\n    \n    def destructure_artist_data(self,artists_list):\n        artist_infos = []\n        artist_genres = []\n        artist_popularities = []\n        artist_followers = []\n        for artist_obj in artists_list:\n            artist_infos.append({\n                \"name\": artist_obj[\"name\"],\n                \"id\": artist_obj[\"id\"],\n                \"genres\": artist_obj.get(\"genres\", []),\n                \"popularity\": artist_obj[\"popularity\"],\n                \"followers\": artist_obj[\"followers\"][\"total\"]\n            })\n            artist_genres.extend(artist_obj.get(\"genres\", []))\n            artist_popularities.append(artist_obj[\"popularity\"])\n            artist_followers.append(artist_obj[\"followers\"][\"total\"])\n        return {\n            'artist_infos' : artist_infos,\n            'artist_genres' : artist_genres,\n            'artist_popularities' : artist_popularities,\n            'artist_followers' : artist_followers,\n        }\n        \n    def get_playlist_by_id(self,playlist_id : str):\n        return self.sp.playlist_tracks(playlist_id = playlist_id)    \n    \n    def construct_track_info_dict(self,track_json = None, audio_features_json = None, artist_json = None): \n        \n        most_popular_artist = max(artist_json['artist_infos'], key=lambda x: x[\"popularity\"])\n        \n        search_str = f\"{track_json['name']} {most_popular_artist['name']}\"\n        \n        lyrics_audio_data = self.yt_scraper.scrap_by_search(search_str=search_str, download_params = self.download_params)\n        \n        track_info = {\n            \"track_name\": track_json[\"name\"],\n            \"track_id\": track_json[\"id\"],\n            \"track_number\": track_json[\"track_number\"],\n            \"disc_number\": track_json[\"disc_number\"],\n            \"duration_ms\": track_json[\"duration_ms\"],\n            \"explicit\": track_json[\"explicit\"],\n            \"popularity\": track_json[\"popularity\"],\n            \"preview_url\": track_json[\"preview_url\"],\n            \"isrc\": track_json[\"external_ids\"].get(\"isrc\"),\n            \"album_name\": track_json[\"album\"][\"name\"],\n            \"album_id\": track_json[\"album\"][\"id\"],\n            \"album_type\": track_json[\"album\"][\"album_type\"],\n            \"album_total_tracks\": track_json[\"album\"][\"total_tracks\"],\n            \"album_release_date\": track_json[\"album\"][\"release_date\"],\n            \"album_release_date_precision\": track_json[\"album\"][\"release_date_precision\"],\n            \"album_images\": track_json[\"album\"][\"images\"],\n            \"popular_artist\": most_popular_artist[\"name\"],\n            \"popular_artist_id\": most_popular_artist[\"id\"],\n            \"artist_names\": [artist[\"name\"] for artist in track_json[\"artists\"]],\n            \"artist_ids\": [artist[\"id\"] for artist in track_json[\"artists\"]],\n            \"combined_genres\": list(set(artist_json['artist_genres'])),\n            \"artist_popularity\": most_popular_artist[\"popularity\"],\n            \"artist_followers\": most_popular_artist[\"followers\"],\n            \"external_url\": track_json[\"external_urls\"][\"spotify\"],\n            \"acousticness\": audio_features_json[\"acousticness\"],\n            \"danceability\": audio_features_json[\"danceability\"],\n            \"energy\": audio_features_json[\"energy\"],\n            \"instrumentalness\": audio_features_json[\"instrumentalness\"],\n            \"key\": audio_features_json[\"key\"],\n            \"liveness\": audio_features_json[\"liveness\"],\n            \"loudness\": audio_features_json[\"loudness\"],\n            \"mode\": audio_features_json[\"mode\"],\n            \"speechiness\": audio_features_json[\"speechiness\"],\n            \"tempo\": audio_features_json[\"tempo\"],\n            \"time_signature\": audio_features_json[\"time_signature\"],\n            \"valence\": audio_features_json[\"valence\"],\n        }\n        track_info.update(lyrics_audio_data)\n        return track_info\n        \n    def _get_single_threaded_data(self,track_obj, audio_feat_obj):\n        artist_ids_list = [artist['id'] for artist in track_obj[\"artists\"]]\n        artists_id_str = ','.join(artist_ids_list[:50])\n        artists_data = self.get_several_artist_info_by_id(artists_id_str)[\"artists\"]\n        destructured_artist_data = self.destructure_artist_data(artists_list=artists_data)  \n        return self.construct_track_info_dict(track_obj, audio_feat_obj, destructured_artist_data)\n    \n    def _get_multi_threaded_data(self,tracks_json,audio_features_json, max_workers):\n        data = []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            # List of tasks to be executed by the thread pool\n            tasks = [\n                executor.submit(self._get_single_threaded_data , *args) for args in zip(tracks_json, audio_features_json)\n            ]\n            success = 0\n            fails = 0\n            \n            with tqdm(total=len(tracks_json)) as pbar:\n                for future in concurrent.futures.as_completed(tasks):\n                    try:\n                        data.append(future.result())\n                        pbar.update(1)\n                        success+=1\n                    except Exception as exc:\n                        print(f'Task generated an exception: {exc}') \n                        fails+=1\n            print({'success' : success, 'fail' : fails})\n                \n        return data\n    \n    def _get_multiprocessed_data(self,tracks_json,audio_features_json, max_workers):\n        data = []\n        with multiprocessing.Pool(processes=max_workers) as pool:\n            # List of tasks to be executed by the thread pool\n            tasks = [\n                pool.apply_async(self._get_single_threaded_data , *args) for args in zip(tracks_json, audio_features_json)\n            ]\n            \n            for task in tasks:\n                # try:\n                    result = task.get()\n                    print(result)\n                    data.append(task.get())\n                # except Exception as exc:\n                    # print(f'Task generated an exception: {exc}') \n        return data\n    \n    \n    def get_several_track_data(self, track_ids_list : list[str], parallelization = 0, max_workers = 50, include_audio = True, include_lyrics = True, output_path = \"songs\"):\n        data = []\n        track_ids_list = list(set(track_ids_list))\n        self.download_params['include_audio'] = include_audio\n        self.download_params['include_lyrics'] = include_lyrics\n        self.download_params['output_path'] = output_path\n        with tqdm(total = len(track_ids_list)) as pbar:\n            for idx in range(0,len(track_ids_list),50):\n                track_id_str = \",\".join(track_ids_list[idx:idx+50])\n                tracks_json = self.get_several_track_info_by_id(track_id_str)[\"tracks\"]\n                audio_features_json = self.get_several_audio_feature_by_id(track_ids_str=track_id_str)[\"audio_features\"]\n                if parallelization == 1:\n                    data.extend(self._get_multi_threaded_data(tracks_json,audio_features_json,max_workers))\n                elif False and parallelization == 2:\n                    data.extend(self._get_multiprocessed_data(tracks_json,audio_features_json,max_workers))\n                else:\n                    temp_data = []\n                    for track_obj, audio_feat_obj in zip(tracks_json, audio_features_json):\n                        temp_data.append(self._get_single_threaded_data(track_obj, audio_feat_obj))\n                        pbar.update(1)\n                    data.extend(temp_data)\n                    self.df = pd.concat([self.df,pd.DataFrame(temp_data)],ignore_index = True)\n        return data\n    \n    def get_track_ids_from_playlist(self,*args,**kwargs):\n        playlist_data = self.sp.playlist_tracks(*args,**kwargs)\n        return [item['track']['id'] for item in playlist_data['items']]\n    \n    def get_track_ids_from_album(self,*args,**kwargs):\n        album_data = self.sp.album_tracks(*args,**kwargs)\n        return [item['id'] for item in album_data['items']]\n    \n    \n      ","metadata":{"execution":{"iopub.status.busy":"2024-07-03T18:55:27.99678Z","iopub.execute_input":"2024-07-03T18:55:27.997165Z","iopub.status.idle":"2024-07-03T18:55:28.038774Z","shell.execute_reply.started":"2024-07-03T18:55:27.997132Z","shell.execute_reply":"2024-07-03T18:55:28.037465Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Environment and Authentication","metadata":{}},{"cell_type":"markdown","source":"### Loading in Kaggle Environment","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")\nclient_id = secrets.get_secret(\"SPOTIFY_CLIENT_ID\")\nclient_secret = secrets.get_secret(\"SPOTIFY_CLIENT_SECRET\")\n# redirect_uri = secrets.get_secret(\"REDIRECT_URI\")\nyt_music_oauth_metadata = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:72.0) Gecko/20100101 Firefox/72.0\",\n    \"Accept\": \"*/*\",\n    \"Accept-Language\": \"en-US,en;q=0.5\",\n    \"Content-Type\": \"application/json\",\n    \"X-Goog-AuthUser\": \"0\",\n    \"x-origin\": \"https://music.youtube.com\",\n    \"Cookie\" : secrets.get_secret(\"YT_MUSIC_COOKIE\")\n}\n\nwith open(os.path.join('/kaggle/working/','oauth.json'), 'w') as f:\n    json.dump(yt_music_oauth_metadata, f)\n    \nwith open('/kaggle/working/tokens.json','w') as f:\n    json.dump(eval(secrets.get_secret('YT_TOKEN')), f)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T19:04:39.930824Z","iopub.execute_input":"2024-07-03T19:04:39.931551Z","iopub.status.idle":"2024-07-03T19:04:42.252456Z","shell.execute_reply.started":"2024-07-03T19:04:39.931517Z","shell.execute_reply":"2024-07-03T19:04:42.25153Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"markdown","source":"## Scrapper Instance","metadata":{}},{"cell_type":"code","source":"scrapper = SpotifyScraper(\n  client_id=client_id,\n  client_secret=client_secret,\n#   redirect_uri=redirect_uri,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T19:04:42.254183Z","iopub.execute_input":"2024-07-03T19:04:42.254613Z","iopub.status.idle":"2024-07-03T19:04:43.657935Z","shell.execute_reply.started":"2024-07-03T19:04:42.254578Z","shell.execute_reply":"2024-07-03T19:04:43.656806Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"# with open('/kaggle/working/tokens.json','r') as f:\n#     dic = json.load(f)\n    \n# print(dic)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading songs json\nwith open('/kaggle/input/spotify-metadata-audio-dataset-001/songs.json','r') as f:\n    songs_list = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T19:04:54.729105Z","iopub.execute_input":"2024-07-03T19:04:54.730004Z","iopub.status.idle":"2024-07-03T19:04:54.744322Z","shell.execute_reply.started":"2024-07-03T19:04:54.72996Z","shell.execute_reply":"2024-07-03T19:04:54.743318Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"track_ids = songs_list[0:8400] \n# track_ids = songs_list[8400:16800] \n# track_ids = songs_list[16800:]","metadata":{"execution":{"iopub.status.busy":"2024-07-03T19:04:54.746261Z","iopub.execute_input":"2024-07-03T19:04:54.74689Z","iopub.status.idle":"2024-07-03T19:04:54.751891Z","shell.execute_reply.started":"2024-07-03T19:04:54.746853Z","shell.execute_reply":"2024-07-03T19:04:54.750774Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"try:\n    track_data = scrapper.get_several_track_data(\n        track_ids[:10],\n        parallelization=0,\n        output_path = 'dataset/songs', \n        include_audio = False, \n        include_lyrics = True,\n        max_workers = 1,\n    )\n    track_data_df = pd.DataFrame(track_data)\n    track_data_df.to_pickle('dataset/total_data.pkl')\n    scrapper.df.to_pickle('dataset/extracted_data.pkl')\nexcept:\n    scrapper.df.to_pickle('dataset/extracted_data.pkl')\n    !kaggle datasets version -m \"Ishan 0 to 8400 metadata done\" -p /kaggle/working/dataset --dir-mode tar","metadata":{"execution":{"iopub.status.busy":"2024-07-03T19:04:56.859956Z","iopub.execute_input":"2024-07-03T19:04:56.861192Z","iopub.status.idle":"2024-07-03T19:05:06.085078Z","shell.execute_reply.started":"2024-07-03T19:04:56.861114Z","shell.execute_reply":"2024-07-03T19:05:06.084119Z"},"trusted":true},"execution_count":164,"outputs":[{"name":"stderr","text":"100%|██████████| 10/10 [00:09<00:00,  1.07it/s]/tmp/ipykernel_33/3295455814.py:254: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  self.df = pd.concat([self.df,pd.DataFrame(temp_data)],ignore_index = True)\n100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"try:\n    audio_output_paths  = scrapper.yt_scraper.threaded_download_song_by_video_id_list(track_data_df.video_id.to_numpy(), 'dataset/songs', max_workers = 50)\n    track_data_df['audio_file_path'] = audio_output_paths\n    scrapper.df['audio_file_path'] = audio_output_paths\n    track_data_df.to_pickle('dataset/total_data.pkl')\n    scrapper.df.to_pickle('dataset/extracted_data.pkl')\n    !kaggle datasets version -m \"Ishan 0 to 8400 audio done\" -p /kaggle/working/dataset --dir-mode tar\nexcept:\n    audio_output_paths = scrapper.yt_scraper.threaded_download_song_by_video_id_list(scrapper.df.video_id.to_numpy(), 'dataset/songs', max_workers = 50)\n    scrapper.df['audio_file_path'] = audio_output_paths\n    !kaggle datasets version -m \"Ishan 0 to 8400 salavge\" -p /kaggle/working/dataset --dir-mode tar","metadata":{"execution":{"iopub.status.busy":"2024-07-03T19:05:06.086671Z","iopub.execute_input":"2024-07-03T19:05:06.087031Z","iopub.status.idle":"2024-07-03T19:05:28.739998Z","shell.execute_reply.started":"2024-07-03T19:05:06.087001Z","shell.execute_reply":"2024-07-03T19:05:28.738807Z"},"trusted":true},"execution_count":165,"outputs":[{"name":"stderr","text":"100%|██████████| 10/10 [00:14<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"{'success': 10, 'fail': 0}\nStarting upload for file total_data.pkl\n100%|██████████████████████████████████████| 20.2k/20.2k [00:00<00:00, 26.8kB/s]\nUpload successful: total_data.pkl (20KB)\nStarting upload for file extracted_data.pkl\n100%|██████████████████████████████████████| 19.9k/19.9k [00:00<00:00, 23.4kB/s]\nUpload successful: extracted_data.pkl (20KB)\nStarting upload for file songs.tar\n100%|██████████████████████████████████████| 5.60M/5.60M [00:01<00:00, 3.05MB/s]\nUpload successful: songs.tar (6MB)\nDataset version is being created. Please check progress at https://www.kaggle.com/ishansrivastava1308/spotify-dataset\n","output_type":"stream"}]}]}